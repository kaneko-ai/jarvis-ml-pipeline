"""JARVIS Research OS - Streamlit Dashboard (Phase 4)."""

import json
import streamlit as st
from pathlib import Path


# --- Page config ---
st.set_page_config(
    page_title="JARVIS Research OS",
    page_icon="ğŸ”¬",
    layout="wide",
)


# --- Helper functions ---
@st.cache_data
def load_papers(json_path):
    """Load papers from a JSON file."""
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)


def get_json_files():
    """Find all JSON files in logs/search/."""
    search_dir = Path("logs/search")
    if not search_dir.exists():
        return []
    files = sorted(search_dir.glob("*.json"), key=lambda f: f.stat().st_mtime, reverse=True)
    return [str(f) for f in files]


def get_note_files():
    """Find all note files in logs/notes/."""
    notes_dir = Path("logs/notes")
    if not notes_dir.exists():
        return []
    files = sorted(notes_dir.glob("*.md"), key=lambda f: f.stat().st_mtime, reverse=True)
    return [str(f) for f in files]


def filter_papers(papers, keyword, year_range, sources):
    """Filter papers by keyword, year range, and source."""
    filtered = []
    for p in papers:
        # Keyword filter
        if keyword:
            kw = keyword.lower()
            searchable = " ".join([
                p.get("title", ""),
                p.get("abstract", ""),
                p.get("summary_ja", ""),
                p.get("journal", ""),
                " ".join(p.get("authors", [])),
                " ".join(p.get("keywords", [])),
                " ".join(p.get("mesh_terms", [])),
            ]).lower()
            if kw not in searchable:
                continue

        # Year filter
        year = p.get("year")
        if year and isinstance(year, (int, float)):
            if not (year_range[0] <= year <= year_range[1]):
                continue

        # Source filter
        if sources and p.get("source", "") not in sources:
            continue

        filtered.append(p)
    return filtered


def make_bibtex_entry(p, index):
    """Generate a single BibTeX entry."""
    authors = " and ".join(p.get("authors", ["Unknown"])[:5])
    title = p.get("title", "Untitled")
    journal = p.get("journal", "")
    year = p.get("year", "n.d.")
    doi = p.get("doi", "")
    pmid = p.get("pmid", "")

    key = f"paper{index}_{year}"
    lines = [f"@article{{{key},"]
    lines.append(f"  author = {{{authors}}},")
    lines.append(f"  title = {{{title}}},")
    if journal:
        lines.append(f"  journal = {{{journal}}},")
    lines.append(f"  year = {{{year}}},")
    if doi:
        lines.append(f"  doi = {{{doi}}},")
    if pmid:
        lines.append(f"  pmid = {{{pmid}}},")
    lines.append("}")
    return "\n".join(lines)


# --- Sidebar ---
st.sidebar.title("JARVIS Research OS")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    ["ğŸ“š è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ğŸ“ ç ”ç©¶ãƒãƒ¼ãƒˆ", "ğŸ“Š çµ±è¨ˆæƒ…å ±"],
)

st.sidebar.markdown("---")
st.sidebar.markdown("**åé›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿**")

json_files = get_json_files()
note_files = get_note_files()

# Show dataset selector in sidebar
selected_file = st.sidebar.selectbox(
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
    json_files,
    format_func=lambda x: Path(x).stem,
) if json_files else None


# --- Main content ---

if page == "ğŸ“š è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹":
    st.title("ğŸ“š è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")

    if not selected_file:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšè«–æ–‡ã‚’æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚")
        st.code('python -m jarvis_cli search "PD-1" --max 20 --json', language="powershell")
        st.stop()

    papers = load_papers(selected_file)
    st.info(f"**{Path(selected_file).stem}** â€” {len(papers)} ä»¶ã®è«–æ–‡")

    # --- Filters ---
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        keyword = st.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢", placeholder="ä¾‹: immunotherapy, autophagy")

    with col2:
        years = [p.get("year", 2024) for p in papers if isinstance(p.get("year"), (int, float))]
        if years:
            min_year, max_year = int(min(years)), int(max(years))
        else:
            min_year, max_year = 2000, 2026
        year_range = st.slider("ğŸ“… å¹´ä»£", min_year, max_year, (min_year, max_year))

    with col3:
        all_sources = sorted(set(p.get("source", "unknown") for p in papers))
        sources = st.multiselect("ğŸ“ ã‚½ãƒ¼ã‚¹", all_sources, default=all_sources)

    # Apply filters
    filtered = filter_papers(papers, keyword, year_range, sources)
    st.markdown(f"**è¡¨ç¤ºä¸­: {len(filtered)} / {len(papers)} ä»¶**")

    # --- BibTeX download ---
    if filtered:
        all_bib = "\n\n".join(make_bibtex_entry(p, i) for i, p in enumerate(filtered, 1))
        st.download_button(
            "ğŸ“¥ BibTeX ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=all_bib,
            file_name=f"{Path(selected_file).stem}.bib",
            mime="text/plain",
        )

    # --- Paper list ---
    st.markdown("---")

    for i, p in enumerate(filtered, 1):
        title = p.get("title", "Untitled")
        year = p.get("year", "n.d.")
        journal = p.get("journal", "")
        authors = p.get("authors", [])
        source = p.get("source", "")
        doi = p.get("doi", "")
        pmid = p.get("pmid", "")
        url = p.get("url", "")
        evidence = p.get("evidence_level", "")
        summary = p.get("summary_ja", "")
        abstract = p.get("abstract", "")

        # Author string
        a_str = ", ".join(authors[:3])
        if len(authors) > 3:
            a_str += f" et al. ({len(authors)} authors)"

        # Paper card
        with st.expander(f"**[{i}] {title}** ({year}) â€” {journal}"):
            if a_str:
                st.markdown(f"**è‘—è€…:** {a_str}")
            st.markdown(f"**å¹´:** {year} | **ã‚½ãƒ¼ã‚¹:** {source}")
            if evidence and evidence != "N/A":
                st.markdown(f"**CEBM ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«:** {evidence}")

            # Links
            links = []
            if url:
                links.append(f"[è«–æ–‡ãƒªãƒ³ã‚¯]({url})")
            if doi:
                links.append(f"[DOI](https://doi.org/{doi})")
            if pmid:
                links.append(f"[PubMed](https://pubmed.ncbi.nlm.nih.gov/{pmid}/)")
            if links:
                st.markdown(" | ".join(links))

            if summary and not summary.startswith("ï¼ˆ"):
                st.markdown("**æ—¥æœ¬èªè¦ç´„:**")
                st.markdown(summary)

            if abstract:
                st.markdown("**Abstract:**")
                st.markdown(f"<details><summary>Click to expand</summary>{abstract}</details>", unsafe_allow_html=True)


elif page == "ğŸ“ ç ”ç©¶ãƒãƒ¼ãƒˆ":
    st.title("ğŸ“ ç ”ç©¶ãƒãƒ¼ãƒˆ")

    if not note_files:
        st.warning("ç ”ç©¶ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        st.code('python -m jarvis_cli note logs/search/PD-1_final.json --provider gemini', language="powershell")
        st.stop()

    selected_note = st.selectbox(
        "ç ”ç©¶ãƒãƒ¼ãƒˆã‚’é¸æŠ",
        note_files,
        format_func=lambda x: Path(x).stem,
    )

    if selected_note:
        content = Path(selected_note).read_text(encoding="utf-8")
        st.markdown(content)

        st.download_button(
            "ğŸ“¥ Markdown ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=content,
            file_name=Path(selected_note).name,
            mime="text/markdown",
        )


elif page == "ğŸ“Š çµ±è¨ˆæƒ…å ±":
    st.title("ğŸ“Š çµ±è¨ˆæƒ…å ±")

    if not selected_file:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    papers = load_papers(selected_file)

    col1, col2, col3 = st.columns(3)
    col1.metric("ç·è«–æ–‡æ•°", len(papers))

    has_summary = sum(1 for p in papers if p.get("summary_ja") and not p["summary_ja"].startswith("ï¼ˆ"))
    col2.metric("è¦ç´„ã‚ã‚Š", has_summary)

    has_doi = sum(1 for p in papers if p.get("doi"))
    col3.metric("DOI ã‚ã‚Š", has_doi)

    # Year distribution
    st.markdown("### å¹´ä»£åˆ†å¸ƒ")
    years = [p.get("year") for p in papers if isinstance(p.get("year"), (int, float))]
    if years:
        year_counts = {}
        for y in years:
            y = int(y)
            year_counts[y] = year_counts.get(y, 0) + 1
        sorted_years = sorted(year_counts.items())
        st.bar_chart(dict(sorted_years))

    # Source distribution
    st.markdown("### ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ")
    source_counts = {}
    for p in papers:
        s = p.get("source", "unknown")
        source_counts[s] = source_counts.get(s, 0) + 1
    st.bar_chart(source_counts)

    # Journal distribution (top 10)
    st.markdown("### ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«åˆ†å¸ƒï¼ˆä¸Šä½10ï¼‰")
    journal_counts = {}
    for p in papers:
        j = p.get("journal", "")
        if j:
            journal_counts[j] = journal_counts.get(j, 0) + 1
    if journal_counts:
        top_journals = sorted(journal_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        st.bar_chart(dict(top_journals))

    # Evidence level distribution
    st.markdown("### ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ")
    evidence_counts = {}
    for p in papers:
        ev = p.get("evidence_level", "N/A")
        if ev:
            evidence_counts[ev] = evidence_counts.get(ev, 0) + 1
    if evidence_counts:
        st.bar_chart(evidence_counts)
