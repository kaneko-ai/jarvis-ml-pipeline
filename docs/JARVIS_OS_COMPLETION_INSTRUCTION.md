# JARVIS Research OS å®Œé‚æŒ‡ç¤ºæ›¸
## antigravityå‘ã‘å®Ÿè¡Œè¨ˆç”»æ›¸ v1.0

> **Authority**: INSTRUCTION (å®Ÿè¡Œãƒ¬ãƒ™ãƒ«)  
> **Repository**: https://github.com/kaneko-ai/jarvis-ml-pipeline  
> **Created**: 2026-01-07  
> **Target**: 120/100ç‚¹ (1200/1000) é”æˆ  
> **Estimated Duration**: 8é€±é–“ (40å–¶æ¥­æ—¥)

---

## ç›®æ¬¡

1. [å®Ÿè¡Œå‰ææ¡ä»¶](#1-å®Ÿè¡Œå‰ææ¡ä»¶)
2. [ã‚¹ã‚­ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ´»ç”¨ã‚¬ã‚¤ãƒ‰](#2-ã‚¹ã‚­ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ´»ç”¨ã‚¬ã‚¤ãƒ‰)
3. [Phase 1: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰å®Œæˆ](#3-phase-1-ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰å®Œæˆ-80ç‚¹)
4. [Phase 2: åŸ‹ã‚è¾¼ã¿ãƒ»æ¤œç´¢å®Œæˆ](#4-phase-2-åŸ‹ã‚è¾¼ã¿æ¤œç´¢å®Œæˆ-46ç‚¹)
5. [Phase 3: å·®åˆ¥åŒ–æ©Ÿèƒ½å®Œæˆ](#5-phase-3-å·®åˆ¥åŒ–æ©Ÿèƒ½å®Œæˆ-100ç‚¹)
6. [Phase 4: ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ å®Œæˆ](#6-phase-4-ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ å®Œæˆ-96ç‚¹)
7. [æ¤œè¨¼ãƒ»å“è³ªä¿è¨¼](#7-æ¤œè¨¼å“è³ªä¿è¨¼)
8. [å®Œäº†åˆ¤å®šåŸºæº–](#8-å®Œäº†åˆ¤å®šåŸºæº–)

---

## 1. å®Ÿè¡Œå‰ææ¡ä»¶

### 1.1 ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/kaneko-ai/jarvis-ml-pipeline.git
cd jarvis-ml-pipeline

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync --all-extras

# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚
uv sync --group dev

# Ollamaã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
ollama --version || echo "Ollamaã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: https://ollama.com/"

# ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ«
ollama pull llama3.2:8b
ollama pull mistral:7b
```

### 1.2 ã‚¹ã‚­ãƒ«å‚ç…§ãƒ‘ã‚¹

```
skills/
â”œâ”€â”€ BRAIN.md      # è¦ä»¶å®šç¾©
â”œâ”€â”€ SPEC.md       # å®Ÿè£…è¨ˆç”»
â”œâ”€â”€ TDD.md        # ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™º
â”œâ”€â”€ ORCH.md       # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ VERIFY.md     # æ¤œè¨¼
â”œâ”€â”€ REVIEW.md     # ãƒ¬ãƒ“ãƒ¥ãƒ¼
â”œâ”€â”€ FINISH.md     # çµ±åˆ
â”œâ”€â”€ DBG.md        # ãƒ‡ãƒãƒƒã‚°
â”œâ”€â”€ WORKTREE.md   # ä¸¦è¡Œä½œæ¥­
â””â”€â”€ PARA.md       # ä¸¦åˆ—å®Ÿè¡Œ
```

### 1.3 å®Ÿè¡Œãƒ•ãƒ­ãƒ¼æ¨™æº–

```
å„ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼:
1. BRAIN â†’ è¦ä»¶ç¢ºèªï¼ˆã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è©²å½“ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‚ç…§ï¼‰
2. SPEC â†’ 2-5åˆ†ã‚¿ã‚¹ã‚¯ã«åˆ†è§£æ¸ˆã¿ï¼ˆä¸‹è¨˜å‚ç…§ï¼‰
3. WORKTREE â†’ éš”é›¢ãƒ–ãƒ©ãƒ³ãƒä½œæˆ
4. ORCH â†’ TDD + VERIFY ã§ã‚µãƒ–ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
5. REVIEW â†’ ä»•æ§˜é©åˆ + å“è³ªãƒã‚§ãƒƒã‚¯
6. FINISH â†’ ãƒãƒ¼ã‚¸ã¾ãŸã¯PRä½œæˆ
```

---

## 2. ã‚¹ã‚­ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ´»ç”¨ã‚¬ã‚¤ãƒ‰

### 2.1 æœ¬æŒ‡ç¤ºæ›¸ã®ä½¿ã„æ–¹

```yaml
æŒ‡ç¤ºæ›¸æ§‹é€ :
  - å„Phaseã¯ç‹¬ç«‹ã—ã¦å®Ÿè¡Œå¯èƒ½
  - å„ã‚¿ã‚¹ã‚¯ã¯ SPEC.md å½¢å¼ã§2-5åˆ†ç²’åº¦ã«åˆ†è§£æ¸ˆã¿
  - ä¾å­˜é–¢ä¿‚ãŒã‚ã‚‹å ´åˆã¯æ˜è¨˜
  - æœŸå¾…å‡ºåŠ›ã¨æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰ã‚’å„ã‚¿ã‚¹ã‚¯ã«è¨˜è¼‰

å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³:
  æ–°æ©Ÿèƒ½é–‹ç™º: BRAIN(ã‚¹ã‚­ãƒƒãƒ—å¯) â†’ SPEC(æœ¬æ›¸å‚ç…§) â†’ WORKTREE â†’ ORCH(TDD+VERIFY) â†’ REVIEW â†’ FINISH
  ãƒã‚°ä¿®æ­£: DBG â†’ TDD â†’ VERIFY â†’ REVIEW â†’ FINISH
  ä¸¦è¡Œä½œæ¥­: PARA ã§è¤‡æ•°ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚é€²è¡Œ
```

### 2.2 ã‚³ãƒŸãƒƒãƒˆè¦ç´„

```
feat: æ–°æ©Ÿèƒ½è¿½åŠ 
fix: ãƒã‚°ä¿®æ­£
refactor: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
test: ãƒ†ã‚¹ãƒˆè¿½åŠ 
docs: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
chore: ãã®ä»–

ä¾‹: feat(offline): implement graceful degradation for network loss
```

---

## 3. Phase 1: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰å®Œæˆ (+80ç‚¹)

### 3.1 æ¦‚è¦

| é …ç›® | å€¤ |
|------|-----|
| ç›®æ¨™ã‚¹ã‚³ã‚¢ | +80ç‚¹ |
| æ¨å®šå·¥æ•° | 10æ—¥ |
| å„ªå…ˆåº¦ | ğŸ”´ æœ€é«˜ |
| ä¾å­˜é–¢ä¿‚ | network/detector.py (å®Œäº†æ¸ˆã¿) |

### 3.2 ã‚¿ã‚¹ã‚¯ 1.5.1: ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ãƒ‡ã‚°ãƒ¬ãƒ¼ãƒ‰å®Œæˆ (+15ç‚¹)

#### è¦ä»¶

```yaml
ç›®çš„: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ‡æ–­æ™‚ã«æ©Ÿèƒ½ã‚’æ®µéšçš„ã«ç¸®é€€ã•ã›ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’ç¶­æŒ
æˆåŠŸæ¡ä»¶:
  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã®æ¤œç´¢ãŒå‹•ä½œ
  - å¤–éƒ¨APIå‘¼ã³å‡ºã—ãŒè‡ªå‹•çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹
  - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¸®é€€çŠ¶æ…‹ãŒæ˜ç¤ºã•ã‚Œã‚‹
éç›®æ¨™:
  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã®æ–°è¦è«–æ–‡å–å¾—ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¾©å¸°å¾Œã«å®Ÿè¡Œï¼‰
```

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 3.2.1 DegradationLevel Enumä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/network/degradation.py
  å†…å®¹:
    from enum import Enum
    
    class DegradationLevel(Enum):
        FULL = "full"           # å…¨æ©Ÿèƒ½åˆ©ç”¨å¯èƒ½
        LIMITED = "limited"     # å¤–éƒ¨APIç„¡åŠ¹ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿
        OFFLINE = "offline"     # å®Œå…¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³
        CRITICAL = "critical"   # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚åˆ©ç”¨ä¸å¯
  æ¤œè¨¼: python -c "from jarvis_core.network.degradation import DegradationLevel; print(DegradationLevel.FULL)"

â–¡ 3.2.2 DegradationManager ã‚¯ãƒ©ã‚¹ä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/network/degradation.py (è¿½è¨˜)
  å†…å®¹:
    @dataclass
    class DegradationManager:
        _current_level: DegradationLevel = DegradationLevel.FULL
        _listeners: List[Callable] = field(default_factory=list)
        
        def get_level(self) -> DegradationLevel:
            return self._current_level
        
        def set_level(self, level: DegradationLevel) -> None:
            old_level = self._current_level
            self._current_level = level
            if old_level != level:
                self._notify_listeners(old_level, level)
        
        def add_listener(self, callback: Callable[[DegradationLevel, DegradationLevel], None]) -> None:
            self._listeners.append(callback)
        
        def _notify_listeners(self, old: DegradationLevel, new: DegradationLevel) -> None:
            for listener in self._listeners:
                listener(old, new)
  æ¤œè¨¼: pytest tests/network/test_degradation.py -v

â–¡ 3.2.3 è‡ªå‹•ãƒ¬ãƒ™ãƒ«åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/network/degradation.py (è¿½è¨˜)
  å†…å®¹:
    def auto_detect_level(self) -> DegradationLevel:
        from jarvis_core.network import is_online
        from jarvis_core.cache import MultiLevelCache
        
        if is_online():
            return DegradationLevel.FULL
        
        cache = MultiLevelCache()
        if cache.get_stats().total_entries > 0:
            return DegradationLevel.LIMITED
        
        return DegradationLevel.OFFLINE
  æ¤œè¨¼: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ‡æ–­çŠ¶æ…‹ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

â–¡ 3.2.4 APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ãƒƒãƒ‘ãƒ¼ä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/network/api_wrapper.py
  å†…å®¹:
    def degradation_aware(func):
        """ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            manager = get_degradation_manager()
            if manager.get_level() in (DegradationLevel.LIMITED, DegradationLevel.OFFLINE):
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
                cache_key = compute_cache_key(func.__name__, args, kwargs)
                cached = get_cache().get(cache_key)
                if cached:
                    return cached
                raise OfflineError(f"Offline mode: {func.__name__} unavailable")
            return func(*args, **kwargs)
        return wrapper
  æ¤œè¨¼: pytest tests/network/test_api_wrapper.py -v

â–¡ 3.2.5 æ—¢å­˜APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é©ç”¨ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sources/pubmed_client.py, semantic_scholar.py, etc.
  å¤‰æ›´:
    @degradation_aware
    def search(self, query: str, ...) -> List[Paper]:
        ...
  æ¤œè¨¼: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ jarvis search "test" å®Ÿè¡Œ

â–¡ 3.2.6 ãƒ†ã‚¹ãƒˆä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/network/test_degradation.py
  å†…å®¹:
    - test_degradation_level_enum
    - test_manager_level_change
    - test_auto_detect_online
    - test_auto_detect_offline
    - test_api_wrapper_fallback
  æ¤œè¨¼: pytest tests/network/test_degradation.py -v --cov
```

#### æœŸå¾…æˆæœç‰©

```
jarvis_core/network/
â”œâ”€â”€ __init__.py (æ›´æ–°: DegradationLevel, DegradationManager exportè¿½åŠ )
â”œâ”€â”€ detector.py (æ—¢å­˜)
â”œâ”€â”€ degradation.py (æ–°è¦)
â””â”€â”€ api_wrapper.py (æ–°è¦)

tests/network/
â”œâ”€â”€ test_detector.py (æ—¢å­˜)
â”œâ”€â”€ test_degradation.py (æ–°è¦)
â””â”€â”€ test_api_wrapper.py (æ–°è¦)
```

---

### 3.3 ã‚¿ã‚¹ã‚¯ 1.5.2: --offlineãƒ•ãƒ©ã‚°å®Ÿè£… (+15ç‚¹)

#### è¦ä»¶

```yaml
ç›®çš„: CLIã‹ã‚‰æ˜ç¤ºçš„ã«ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã‚’æŒ‡å®šå¯èƒ½ã«ã™ã‚‹
æˆåŠŸæ¡ä»¶:
  - jarvis --offline search "query" ãŒå‹•ä½œ
  - jarvis --offline run ãŒå‹•ä½œ
  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’è©¦è¡Œã—ãªã„
```

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 3.3.1 CLIã«ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´:
    @click.option('--offline', is_flag=True, help='Run in offline mode (no network access)')
    @click.pass_context
    def cli(ctx, offline: bool):
        ctx.ensure_object(dict)
        ctx.obj['offline'] = offline
        if offline:
            from jarvis_core.network import DegradationManager, DegradationLevel
            manager = DegradationManager()
            manager.set_level(DegradationLevel.OFFLINE)
  æ¤œè¨¼: jarvis --offline --help

â–¡ 3.3.2 searchã‚³ãƒãƒ³ãƒ‰ã«ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œè¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´:
    @cli.command()
    @click.pass_context
    def search(ctx, query: str, ...):
        offline = ctx.obj.get('offline', False)
        if offline:
            # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã¿æ¤œç´¢
            results = local_search(query)
        else:
            results = unified_search(query)
  æ¤œè¨¼: jarvis --offline search "machine learning"

â–¡ 3.3.3 runã‚³ãƒãƒ³ãƒ‰ã«ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œè¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´: åŒæ§˜ã«offlineãƒ•ãƒ©ã‚°ã‚’run_taskã«ä¼æ’­
  æ¤œè¨¼: jarvis --offline run --goal "test"

â–¡ 3.3.4 ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤ºè¿½åŠ  (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´:
    if offline:
        click.echo(click.style("ğŸ”Œ Offline Mode: Using local cache only", fg='yellow'))
  æ¤œè¨¼: jarvis --offline search "test" ã§é»„è‰²ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º

â–¡ 3.3.5 ç’°å¢ƒå¤‰æ•°å¯¾å¿œ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´:
    offline = offline or os.getenv('JARVIS_OFFLINE', '').lower() == 'true'
  æ¤œè¨¼: JARVIS_OFFLINE=true jarvis search "test"

â–¡ 3.3.6 ãƒ†ã‚¹ãƒˆä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/cli/test_offline_flag.py
  å†…å®¹:
    - test_offline_flag_sets_degradation_level
    - test_offline_search_uses_local_cache
    - test_offline_env_var
    - test_offline_mode_message_displayed
  æ¤œè¨¼: pytest tests/cli/test_offline_flag.py -v
```

#### æœŸå¾…æˆæœç‰©

```
jarvis_cli.py (æ›´æ–°)
tests/cli/test_offline_flag.py (æ–°è¦)
```

---

### 3.4 ã‚¿ã‚¹ã‚¯ 1.5.3: åŒæœŸã‚­ãƒ¥ãƒ¼å®Ÿè£… (+25ç‚¹)

#### è¦ä»¶

```yaml
ç›®çš„: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã®æ“ä½œã‚’ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¾©å¸°æ™‚ã«å®Ÿè¡Œ
æˆåŠŸæ¡ä»¶:
  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã®APIå‘¼ã³å‡ºã—ãŒã‚­ãƒ¥ãƒ¼ã«ä¿å­˜ã•ã‚Œã‚‹
  - ã‚­ãƒ¥ãƒ¼ã¯SQLiteã«æ°¸ç¶šåŒ–ã•ã‚Œã‚‹
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¾©å¸°æ™‚ã«è‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹
  - é‡è¤‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯çµ±åˆã•ã‚Œã‚‹
```

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 3.4.1 SyncQueueã‚¹ã‚­ãƒ¼ãƒå®šç¾© (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sync/schema.py
  å†…å®¹:
    from dataclasses import dataclass
    from datetime import datetime
    from enum import Enum
    from typing import Any, Dict, Optional
    
    class QueueItemStatus(Enum):
        PENDING = "pending"
        PROCESSING = "processing"
        COMPLETED = "completed"
        FAILED = "failed"
    
    @dataclass
    class QueueItem:
        id: str
        operation: str  # "search", "fetch_paper", "fetch_citations"
        params: Dict[str, Any]
        status: QueueItemStatus = QueueItemStatus.PENDING
        created_at: datetime = field(default_factory=datetime.utcnow)
        processed_at: Optional[datetime] = None
        error: Optional[str] = None
        retry_count: int = 0
        
        def to_dict(self) -> Dict[str, Any]:
            return {
                "id": self.id,
                "operation": self.operation,
                "params": self.params,
                "status": self.status.value,
                "created_at": self.created_at.isoformat(),
                "processed_at": self.processed_at.isoformat() if self.processed_at else None,
                "error": self.error,
                "retry_count": self.retry_count,
            }
  æ¤œè¨¼: python -c "from jarvis_core.sync.schema import QueueItem; print(QueueItem)"

â–¡ 3.4.2 SQLiteã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sync/storage.py
  å†…å®¹:
    import sqlite3
    from pathlib import Path
    from typing import List, Optional
    
    class SyncQueueStorage:
        def __init__(self, db_path: str = "~/.jarvis/sync_queue.db"):
            self.db_path = Path(db_path).expanduser()
            self.db_path.parent.mkdir(parents=True, exist_ok=True)
            self._init_db()
        
        def _init_db(self) -> None:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS sync_queue (
                        id TEXT PRIMARY KEY,
                        operation TEXT NOT NULL,
                        params TEXT NOT NULL,
                        status TEXT DEFAULT 'pending',
                        created_at TEXT NOT NULL,
                        processed_at TEXT,
                        error TEXT,
                        retry_count INTEGER DEFAULT 0
                    )
                ''')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_status ON sync_queue(status)')
        
        def add(self, item: QueueItem) -> None:
            ...
        
        def get_pending(self, limit: int = 100) -> List[QueueItem]:
            ...
        
        def update_status(self, item_id: str, status: QueueItemStatus, error: Optional[str] = None) -> None:
            ...
        
        def remove_completed(self, older_than_days: int = 7) -> int:
            ...
  æ¤œè¨¼: pytest tests/sync/test_storage.py -v

â–¡ 3.4.3 SyncQueueManagerå®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sync/manager.py
  å†…å®¹:
    class SyncQueueManager:
        def __init__(self):
            self.storage = SyncQueueStorage()
            self._handlers: Dict[str, Callable] = {}
        
        def register_handler(self, operation: str, handler: Callable) -> None:
            self._handlers[operation] = handler
        
        def enqueue(self, operation: str, params: Dict[str, Any]) -> str:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            existing = self._find_duplicate(operation, params)
            if existing:
                return existing.id
            
            item = QueueItem(
                id=str(uuid.uuid4()),
                operation=operation,
                params=params,
            )
            self.storage.add(item)
            return item.id
        
        def process_queue(self, max_items: int = 10) -> List[QueueItem]:
            pending = self.storage.get_pending(limit=max_items)
            results = []
            
            for item in pending:
                handler = self._handlers.get(item.operation)
                if not handler:
                    self.storage.update_status(item.id, QueueItemStatus.FAILED, "No handler")
                    continue
                
                try:
                    self.storage.update_status(item.id, QueueItemStatus.PROCESSING)
                    handler(**item.params)
                    self.storage.update_status(item.id, QueueItemStatus.COMPLETED)
                    item.status = QueueItemStatus.COMPLETED
                except Exception as e:
                    self.storage.update_status(item.id, QueueItemStatus.FAILED, str(e))
                    item.error = str(e)
                
                results.append(item)
            
            return results
        
        def get_queue_status(self) -> Dict[str, int]:
            ...
  æ¤œè¨¼: pytest tests/sync/test_manager.py -v

â–¡ 3.4.4 ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ç™»éŒ² (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sync/handlers.py
  å†…å®¹:
    def register_default_handlers(manager: SyncQueueManager) -> None:
        from jarvis_core.sources import UnifiedSourceClient
        
        client = UnifiedSourceClient()
        
        manager.register_handler("search", lambda query, **kwargs: client.search(query, **kwargs))
        manager.register_handler("fetch_paper", lambda doi: client.get_by_doi(doi))
        manager.register_handler("fetch_citations", lambda paper_id: client.get_citations(paper_id))
  æ¤œè¨¼: python -c "from jarvis_core.sync.handlers import register_default_handlers"

â–¡ 3.4.5 APIãƒ©ãƒƒãƒ‘ãƒ¼ã«ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°çµ±åˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/network/api_wrapper.py (æ›´æ–°)
  å¤‰æ›´:
    def degradation_aware_with_queue(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            manager = get_degradation_manager()
            if manager.get_level() in (DegradationLevel.LIMITED, DegradationLevel.OFFLINE):
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
                cache_key = compute_cache_key(func.__name__, args, kwargs)
                cached = get_cache().get(cache_key)
                if cached:
                    return cached
                
                # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                queue_manager = get_sync_queue_manager()
                queue_id = queue_manager.enqueue(func.__name__, {"args": args, "kwargs": kwargs})
                
                raise OfflineQueuedError(f"Queued for sync: {queue_id}")
            
            return func(*args, **kwargs)
        return wrapper
  æ¤œè¨¼: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³çŠ¶æ…‹ã§APIå‘¼ã³å‡ºã—â†’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

â–¡ 3.4.6 CLIåŒæœŸã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´:
    @cli.command()
    def sync():
        """Process pending sync queue items."""
        from jarvis_core.sync import SyncQueueManager
        from jarvis_core.network import is_online
        
        if not is_online():
            click.echo(click.style("Cannot sync: offline", fg='red'))
            return
        
        manager = SyncQueueManager()
        results = manager.process_queue()
        
        completed = sum(1 for r in results if r.status == QueueItemStatus.COMPLETED)
        failed = sum(1 for r in results if r.status == QueueItemStatus.FAILED)
        
        click.echo(f"Sync complete: {completed} succeeded, {failed} failed")
  æ¤œè¨¼: jarvis sync

â–¡ 3.4.7 ãƒ†ã‚¹ãƒˆä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/sync/test_queue.py
  å†…å®¹:
    - test_queue_item_creation
    - test_storage_add_and_get
    - test_duplicate_detection
    - test_process_queue_success
    - test_process_queue_failure_retry
    - test_cleanup_old_items
  æ¤œè¨¼: pytest tests/sync/ -v --cov
```

#### æœŸå¾…æˆæœç‰©

```
jarvis_core/sync/
â”œâ”€â”€ __init__.py (æ–°è¦)
â”œâ”€â”€ schema.py (æ–°è¦)
â”œâ”€â”€ storage.py (æ–°è¦)
â”œâ”€â”€ manager.py (æ–°è¦)
â””â”€â”€ handlers.py (æ–°è¦)

tests/sync/
â”œâ”€â”€ test_schema.py (æ–°è¦)
â”œâ”€â”€ test_storage.py (æ–°è¦)
â”œâ”€â”€ test_manager.py (æ–°è¦)
â””â”€â”€ test_queue.py (æ–°è¦)
```

---

### 3.5 ã‚¿ã‚¹ã‚¯ 1.5.4: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¾©å¸°åŒæœŸ (+20ç‚¹)

#### è¦ä»¶

```yaml
ç›®çš„: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾©å¸°ã‚’æ¤œå‡ºã—ã€ã‚­ãƒ¥ãƒ¼ã‚’è‡ªå‹•å‡¦ç†
æˆåŠŸæ¡ä»¶:
  - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾©å¸°æ™‚ã«è‡ªå‹•ã§ã‚­ãƒ¥ãƒ¼ã‚’å‡¦ç†
  - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éåŒæœŸå®Ÿè¡Œ
  - å‡¦ç†å®Œäº†é€šçŸ¥
```

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 3.5.1 ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¤‰æ›´ãƒªã‚¹ãƒŠãƒ¼å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/network/listener.py
  å†…å®¹:
    import threading
    import time
    from typing import Callable, List
    
    class NetworkChangeListener:
        def __init__(self, check_interval: float = 5.0):
            self._check_interval = check_interval
            self._callbacks: List[Callable[[bool], None]] = []
            self._last_status: bool = True
            self._running = False
            self._thread: Optional[threading.Thread] = None
        
        def add_callback(self, callback: Callable[[bool], None]) -> None:
            self._callbacks.append(callback)
        
        def start(self) -> None:
            if self._running:
                return
            self._running = True
            self._thread = threading.Thread(target=self._monitor_loop, daemon=True)
            self._thread.start()
        
        def stop(self) -> None:
            self._running = False
            if self._thread:
                self._thread.join(timeout=2.0)
        
        def _monitor_loop(self) -> None:
            from jarvis_core.network import is_online
            
            while self._running:
                current_status = is_online()
                
                if current_status != self._last_status:
                    for callback in self._callbacks:
                        try:
                            callback(current_status)
                        except Exception as e:
                            logger.error(f"Callback error: {e}")
                    
                    self._last_status = current_status
                
                time.sleep(self._check_interval)
  æ¤œè¨¼: pytest tests/network/test_listener.py -v

â–¡ 3.5.2 è‡ªå‹•åŒæœŸã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£… (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sync/auto_sync.py
  å†…å®¹:
    def on_network_restored(is_online: bool) -> None:
        if not is_online:
            return
        
        logger.info("Network restored, starting queue sync...")
        
        manager = SyncQueueManager()
        status = manager.get_queue_status()
        
        if status.get("pending", 0) == 0:
            logger.info("No pending items to sync")
            return
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
        thread = threading.Thread(
            target=_background_sync,
            args=(manager,),
            daemon=True
        )
        thread.start()
    
    def _background_sync(manager: SyncQueueManager) -> None:
        results = manager.process_queue(max_items=50)
        completed = sum(1 for r in results if r.status == QueueItemStatus.COMPLETED)
        logger.info(f"Background sync completed: {completed} items processed")
  æ¤œè¨¼: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ‡æ–­â†’å¾©å¸°ã§è‡ªå‹•åŒæœŸã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

â–¡ 3.5.3 ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ãƒªã‚¹ãƒŠãƒ¼ç™»éŒ² (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/app.py
  å¤‰æ›´:
    def init_app():
        # ... æ—¢å­˜ã®init ...
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒªã‚¹ãƒŠãƒ¼é–‹å§‹
        from jarvis_core.network.listener import NetworkChangeListener
        from jarvis_core.sync.auto_sync import on_network_restored
        
        listener = NetworkChangeListener()
        listener.add_callback(on_network_restored)
        listener.start()
        
        return listener
  æ¤œè¨¼: ã‚¢ãƒ—ãƒªèµ·å‹•å¾Œã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¤‰æ›´ã‚’æ¤œå‡º

â–¡ 3.5.4 åŒæœŸé€²æ—è¡¨ç¤º (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sync/progress.py
  å†…å®¹:
    class SyncProgressReporter:
        def __init__(self):
            self._callbacks: List[Callable[[int, int], None]] = []
        
        def add_callback(self, callback: Callable[[int, int], None]) -> None:
            self._callbacks.append(callback)
        
        def report(self, completed: int, total: int) -> None:
            for callback in self._callbacks:
                callback(completed, total)
  æ¤œè¨¼: åŒæœŸä¸­ã«é€²æ—ãŒå ±å‘Šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

â–¡ 3.5.5 CLIåŒæœŸçŠ¶æ…‹è¡¨ç¤ºã‚³ãƒãƒ³ãƒ‰ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´:
    @cli.command()
    def sync_status():
        """Show sync queue status."""
        from jarvis_core.sync import SyncQueueManager
        
        manager = SyncQueueManager()
        status = manager.get_queue_status()
        
        click.echo("Sync Queue Status:")
        click.echo(f"  Pending:    {status.get('pending', 0)}")
        click.echo(f"  Processing: {status.get('processing', 0)}")
        click.echo(f"  Completed:  {status.get('completed', 0)}")
        click.echo(f"  Failed:     {status.get('failed', 0)}")
  æ¤œè¨¼: jarvis sync-status

â–¡ 3.5.6 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/sync/test_auto_sync.py
  å†…å®¹:
    - test_network_listener_detects_change
    - test_auto_sync_on_network_restored
    - test_background_sync_thread
    - test_progress_reporter
  æ¤œè¨¼: pytest tests/sync/test_auto_sync.py -v
```

#### æœŸå¾…æˆæœç‰©

```
jarvis_core/network/listener.py (æ–°è¦)
jarvis_core/sync/auto_sync.py (æ–°è¦)
jarvis_core/sync/progress.py (æ–°è¦)
tests/sync/test_auto_sync.py (æ–°è¦)
tests/network/test_listener.py (æ–°è¦)
```

---

### 3.6 ã‚¿ã‚¹ã‚¯ 1.5.5: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³çŠ¶æ…‹è¡¨ç¤º (+5ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 3.6.1 çŠ¶æ…‹ãƒãƒŠãƒ¼è¡¨ç¤ºé–¢æ•° (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/ui/status.py
  å†…å®¹:
    from jarvis_core.network import DegradationLevel, get_degradation_manager
    
    def get_status_banner() -> str:
        manager = get_degradation_manager()
        level = manager.get_level()
        
        banners = {
            DegradationLevel.FULL: "",
            DegradationLevel.LIMITED: "âš ï¸  Limited Mode: External APIs unavailable",
            DegradationLevel.OFFLINE: "ğŸ”Œ Offline Mode: Using local cache only",
            DegradationLevel.CRITICAL: "ğŸš¨ Critical: No cache available",
        }
        
        return banners.get(level, "")
  æ¤œè¨¼: python -c "from jarvis_core.ui.status import get_status_banner; print(get_status_banner())"

â–¡ 3.6.2 CLIã«çŠ¶æ…‹è¡¨ç¤ºçµ±åˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´: å„ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå‰ã«ãƒãƒŠãƒ¼è¡¨ç¤º
  æ¤œè¨¼: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã«jarvisã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã§ãƒãƒŠãƒ¼è¡¨ç¤º
```

---

## 4. Phase 2: åŸ‹ã‚è¾¼ã¿ãƒ»æ¤œç´¢å®Œæˆ (+46ç‚¹)

### 4.1 æ¦‚è¦

| é …ç›® | å€¤ |
|------|-----|
| ç›®æ¨™ã‚¹ã‚³ã‚¢ | +46ç‚¹ |
| æ¨å®šå·¥æ•° | 8æ—¥ |
| å„ªå…ˆåº¦ | ğŸŸ  é«˜ |
| ä¾å­˜é–¢ä¿‚ | Phase 1å®Œäº†æ¨å¥¨ |

### 4.2 ã‚¿ã‚¹ã‚¯ 1.2.1: SPECTER2ãƒ¢ãƒ‡ãƒ«è¿½åŠ  (+6ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 4.2.1 SPECTER2ã‚¢ãƒ€ãƒ—ã‚¿ä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/specter2.py
  å†…å®¹:
    from sentence_transformers import SentenceTransformer
    from typing import List
    import numpy as np
    
    class SPECTER2Embedding:
        """AllenAI SPECTER2 for scientific document embedding."""
        
        MODEL_NAME = "allenai/specter2"
        
        def __init__(self, device: str = "auto"):
            self._model: Optional[SentenceTransformer] = None
            self._device = device
        
        def _load_model(self) -> SentenceTransformer:
            if self._model is None:
                device = self._device
                if device == "auto":
                    import torch
                    device = "cuda" if torch.cuda.is_available() else "cpu"
                
                self._model = SentenceTransformer(self.MODEL_NAME, device=device)
            return self._model
        
        def embed(self, texts: List[str]) -> np.ndarray:
            model = self._load_model()
            return model.encode(texts, show_progress_bar=False)
        
        def embed_paper(self, title: str, abstract: str) -> np.ndarray:
            """SPECTER2 recommended format: title + [SEP] + abstract"""
            text = f"{title} [SEP] {abstract}"
            return self.embed([text])[0]
        
        @property
        def dimension(self) -> int:
            return 768
  æ¤œè¨¼: pytest tests/embeddings/test_specter2.py -v

â–¡ 4.2.2 ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ­ã‚¸ãƒƒã‚¯è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/__init__.py
  å¤‰æ›´:
    from .specter2 import SPECTER2Embedding
    
    def get_embedding_model(model_type: str = "general") -> EmbeddingModel:
        if model_type == "scientific":
            return SPECTER2Embedding()
        return SentenceTransformerEmbedding()
  æ¤œè¨¼: python -c "from jarvis_core.embeddings import get_embedding_model; print(get_embedding_model('scientific'))"

â–¡ 4.2.3 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: configs/embedding_config.yml
  å†…å®¹:
    embedding:
      default_model: "general"  # or "scientific"
      models:
        general:
          name: "all-MiniLM-L6-v2"
          dimension: 384
        scientific:
          name: "allenai/specter2"
          dimension: 768
  æ¤œè¨¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ç¢ºèª

â–¡ 4.2.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/embeddings/test_specter2.py
  å†…å®¹:
    - test_specter2_load
    - test_specter2_embed_single
    - test_specter2_embed_paper
    - test_dimension
  æ¤œè¨¼: pytest tests/embeddings/test_specter2.py -v
```

---

### 4.3 ã‚¿ã‚¹ã‚¯ 1.2.2: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢å®Œæˆ (+18ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 4.3.1 BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/bm25.py
  è¿½åŠ å†…å®¹:
    class BM25Index:
        def __init__(self):
            self._index: Optional[BM25Okapi] = None
            self._documents: List[str] = []
            self._doc_ids: List[str] = []
        
        def build(self, documents: List[str], doc_ids: List[str]) -> None:
            from rank_bm25 import BM25Okapi
            
            tokenized = [self._tokenize(doc) for doc in documents]
            self._index = BM25Okapi(tokenized)
            self._documents = documents
            self._doc_ids = doc_ids
        
        def search(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:
            if self._index is None:
                raise ValueError("Index not built")
            
            tokenized_query = self._tokenize(query)
            scores = self._index.get_scores(tokenized_query)
            
            # Top-kå–å¾—
            top_indices = np.argsort(scores)[::-1][:top_k]
            return [(self._doc_ids[i], scores[i]) for i in top_indices]
        
        def _tokenize(self, text: str) -> List[str]:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆæ”¹å–„å¯èƒ½ï¼‰
            return text.lower().split()
        
        def save(self, path: str) -> None:
            import pickle
            with open(path, 'wb') as f:
                pickle.dump({
                    'documents': self._documents,
                    'doc_ids': self._doc_ids,
                }, f)
        
        def load(self, path: str) -> None:
            import pickle
            with open(path, 'rb') as f:
                data = pickle.load(f)
            self.build(data['documents'], data['doc_ids'])
  æ¤œè¨¼: pytest tests/embeddings/test_bm25.py -v

â–¡ 4.3.2 Reciprocal Rank Fusionå®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/hybrid.py
  è¿½åŠ å†…å®¹:
    from enum import Enum
    from typing import List, Tuple, Dict
    
    class FusionMethod(Enum):
        RRF = "rrf"  # Reciprocal Rank Fusion
        WEIGHTED = "weighted"
        COMBSUM = "combsum"
    
    class HybridSearch:
        def __init__(
            self,
            dense_model: SentenceTransformerEmbedding,
            sparse_index: BM25Index,
            fusion_method: FusionMethod = FusionMethod.RRF,
            rrf_k: int = 60,
            dense_weight: float = 0.5,
        ):
            self._dense = dense_model
            self._sparse = sparse_index
            self._fusion = fusion_method
            self._rrf_k = rrf_k
            self._dense_weight = dense_weight
            self._doc_embeddings: Optional[np.ndarray] = None
            self._doc_ids: List[str] = []
        
        def index(self, documents: List[str], doc_ids: List[str]) -> None:
            # Dense embeddings
            self._doc_embeddings = self._dense.embed(documents)
            self._doc_ids = doc_ids
            
            # Sparse index
            self._sparse.build(documents, doc_ids)
        
        def search(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:
            # Dense search
            query_embedding = self._dense.embed([query])[0]
            dense_scores = self._cosine_similarity(query_embedding, self._doc_embeddings)
            dense_results = self._rank_results(dense_scores)
            
            # Sparse search
            sparse_results = self._sparse.search(query, top_k=top_k * 2)
            
            # Fusion
            if self._fusion == FusionMethod.RRF:
                return self._rrf_fusion(dense_results, sparse_results, top_k)
            elif self._fusion == FusionMethod.WEIGHTED:
                return self._weighted_fusion(dense_results, sparse_results, top_k)
            else:
                return self._combsum_fusion(dense_results, sparse_results, top_k)
        
        def _rrf_fusion(
            self,
            dense: List[Tuple[str, float]],
            sparse: List[Tuple[str, float]],
            top_k: int
        ) -> List[Tuple[str, float]]:
            scores: Dict[str, float] = {}
            
            for rank, (doc_id, _) in enumerate(dense):
                scores[doc_id] = scores.get(doc_id, 0) + 1.0 / (self._rrf_k + rank + 1)
            
            for rank, (doc_id, _) in enumerate(sparse):
                scores[doc_id] = scores.get(doc_id, 0) + 1.0 / (self._rrf_k + rank + 1)
            
            sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
            return sorted_results[:top_k]
        
        def _cosine_similarity(self, query: np.ndarray, docs: np.ndarray) -> np.ndarray:
            query_norm = query / np.linalg.norm(query)
            docs_norm = docs / np.linalg.norm(docs, axis=1, keepdims=True)
            return np.dot(docs_norm, query_norm)
        
        def _rank_results(self, scores: np.ndarray) -> List[Tuple[str, float]]:
            indices = np.argsort(scores)[::-1]
            return [(self._doc_ids[i], scores[i]) for i in indices]
  æ¤œè¨¼: pytest tests/embeddings/test_hybrid.py -v

â–¡ 4.3.3 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ– (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/hybrid.py
  è¿½åŠ :
    def save(self, path: str) -> None:
        import json
        import numpy as np
        
        base_path = Path(path)
        base_path.mkdir(parents=True, exist_ok=True)
        
        # Dense embeddings
        np.save(base_path / "dense_embeddings.npy", self._doc_embeddings)
        
        # Doc IDs
        with open(base_path / "doc_ids.json", 'w') as f:
            json.dump(self._doc_ids, f)
        
        # Sparse index
        self._sparse.save(str(base_path / "bm25_index.pkl"))
    
    def load(self, path: str) -> None:
        base_path = Path(path)
        
        self._doc_embeddings = np.load(base_path / "dense_embeddings.npy")
        
        with open(base_path / "doc_ids.json", 'r') as f:
            self._doc_ids = json.load(f)
        
        self._sparse.load(str(base_path / "bm25_index.pkl"))
  æ¤œè¨¼: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ

â–¡ 4.3.4 CLIã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ :
    @cli.command()
    @click.argument('source_dir')
    @click.option('--output', '-o', default='~/.jarvis/index')
    def build_index(source_dir: str, output: str):
        """Build hybrid search index from papers."""
        from jarvis_core.embeddings import HybridSearch, get_embedding_model, BM25Index
        
        # è«–æ–‡èª­ã¿è¾¼ã¿
        papers = load_papers_from_dir(source_dir)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        hybrid = HybridSearch(
            dense_model=get_embedding_model(),
            sparse_index=BM25Index(),
        )
        
        documents = [f"{p.title} {p.abstract}" for p in papers]
        doc_ids = [p.id for p in papers]
        
        hybrid.index(documents, doc_ids)
        hybrid.save(output)
        
        click.echo(f"Index built: {len(papers)} papers -> {output}")
  æ¤œè¨¼: jarvis build-index ./papers -o ./index

â–¡ 4.3.5 ãƒ†ã‚¹ãƒˆä½œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/embeddings/test_hybrid.py
  å†…å®¹:
    - test_hybrid_index_build
    - test_hybrid_search_rrf
    - test_hybrid_search_weighted
    - test_hybrid_save_load
    - test_fusion_method_comparison
  æ¤œè¨¼: pytest tests/embeddings/test_hybrid.py -v --cov
```

---

### 4.4 ã‚¿ã‚¹ã‚¯ 1.2.3: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æœ€é©åŒ– (+12ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 4.4.1 FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/vector_store.py
  å†…å®¹:
    import faiss
    import numpy as np
    from typing import List, Tuple, Optional
    
    class FAISSVectorStore:
        def __init__(self, dimension: int, index_type: str = "flat"):
            self._dimension = dimension
            self._index: Optional[faiss.Index] = None
            self._doc_ids: List[str] = []
            self._index_type = index_type
        
        def build(self, embeddings: np.ndarray, doc_ids: List[str]) -> None:
            if self._index_type == "flat":
                self._index = faiss.IndexFlatIP(self._dimension)
            elif self._index_type == "ivf":
                quantizer = faiss.IndexFlatIP(self._dimension)
                nlist = min(100, len(doc_ids) // 10)
                self._index = faiss.IndexIVFFlat(quantizer, self._dimension, nlist)
                self._index.train(embeddings.astype(np.float32))
            
            # æ­£è¦åŒ–ã—ã¦ã‹ã‚‰è¿½åŠ 
            normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
            self._index.add(normalized.astype(np.float32))
            self._doc_ids = doc_ids
        
        def search(self, query_embedding: np.ndarray, top_k: int = 10) -> List[Tuple[str, float]]:
            query_norm = query_embedding / np.linalg.norm(query_embedding)
            query_norm = query_norm.reshape(1, -1).astype(np.float32)
            
            distances, indices = self._index.search(query_norm, top_k)
            
            results = []
            for i, idx in enumerate(indices[0]):
                if idx != -1:
                    results.append((self._doc_ids[idx], float(distances[0][i])))
            
            return results
        
        def save(self, path: str) -> None:
            faiss.write_index(self._index, f"{path}.faiss")
            with open(f"{path}.ids", 'w') as f:
                json.dump(self._doc_ids, f)
        
        def load(self, path: str) -> None:
            self._index = faiss.read_index(f"{path}.faiss")
            with open(f"{path}.ids", 'r') as f:
                self._doc_ids = json.load(f)
  æ¤œè¨¼: pytest tests/embeddings/test_vector_store.py -v

â–¡ 4.4.2 ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«è¿½åŠ ã‚µãƒãƒ¼ãƒˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/vector_store.py
  è¿½åŠ :
    def add(self, embeddings: np.ndarray, doc_ids: List[str]) -> None:
        normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
        self._index.add(normalized.astype(np.float32))
        self._doc_ids.extend(doc_ids)
  æ¤œè¨¼: è¿½åŠ å¾Œã®æ¤œç´¢ãƒ†ã‚¹ãƒˆ

â–¡ 4.4.3 HybridSearchã«FAISSçµ±åˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/embeddings/hybrid.py
  å¤‰æ›´:
    def __init__(self, ..., use_faiss: bool = True):
        if use_faiss:
            self._vector_store = FAISSVectorStore(dense_model.dimension)
        else:
            self._vector_store = None
  æ¤œè¨¼: FAISSä½¿ç”¨æ™‚ã®æ¤œç´¢ãƒ†ã‚¹ãƒˆ

â–¡ 4.4.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/embeddings/test_vector_store.py
  æ¤œè¨¼: pytest tests/embeddings/test_vector_store.py -v
```

---

### 4.5 ã‚¿ã‚¹ã‚¯ 1.2.4: ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®æ”¹å–„ (+10ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 4.5.1 åœ§ç¸®ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/cache/multi_level.py
  å¤‰æ›´:
    def __init__(self, ..., compression: str = "gzip"):
        self._compression = compression
    
    def _compress(self, data: bytes) -> bytes:
        if self._compression == "gzip":
            import gzip
            return gzip.compress(data)
        elif self._compression == "lz4":
            import lz4.frame
            return lz4.frame.compress(data)
        return data
    
    def _decompress(self, data: bytes) -> bytes:
        if self._compression == "gzip":
            import gzip
            return gzip.decompress(data)
        elif self._compression == "lz4":
            import lz4.frame
            return lz4.frame.decompress(data)
        return data
  æ¤œè¨¼: pytest tests/cache/test_compression.py -v

â–¡ 4.5.2 LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥æ”¹å–„ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/cache/multi_level.py
  å¤‰æ›´:
    from collections import OrderedDict
    
    class LRUCache:
        def __init__(self, max_size: int = 1000):
            self._cache = OrderedDict()
            self._max_size = max_size
        
        def get(self, key: str) -> Optional[Any]:
            if key in self._cache:
                self._cache.move_to_end(key)
                return self._cache[key]
            return None
        
        def put(self, key: str, value: Any) -> None:
            if key in self._cache:
                self._cache.move_to_end(key)
            else:
                if len(self._cache) >= self._max_size:
                    self._cache.popitem(last=False)
            self._cache[key] = value
  æ¤œè¨¼: pytest tests/cache/test_lru.py -v

â–¡ 4.5.3 ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆæ©Ÿèƒ½å¼·åŒ– (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/cache/multi_level.py
  è¿½åŠ :
    def get_detailed_stats(self) -> Dict[str, Any]:
        return {
            "l1_hits": self._l1_hits,
            "l2_hits": self._l2_hits,
            "misses": self._misses,
            "hit_rate": self._calculate_hit_rate(),
            "l1_size": len(self._l1_cache),
            "l2_size": self._get_l2_size(),
            "compression_ratio": self._calculate_compression_ratio(),
        }
  æ¤œè¨¼: python -c "from jarvis_core.cache import MultiLevelCache; print(MultiLevelCache().get_detailed_stats())"

â–¡ 4.5.4 ãƒ†ã‚¹ãƒˆä½œæˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/cache/test_compression.py, tests/cache/test_lru.py
  æ¤œè¨¼: pytest tests/cache/ -v --cov
```

---

## 5. Phase 3: å·®åˆ¥åŒ–æ©Ÿèƒ½å®Œæˆ (+100ç‚¹)

### 5.1 æ¦‚è¦

| é …ç›® | å€¤ |
|------|-----|
| ç›®æ¨™ã‚¹ã‚³ã‚¢ | +100ç‚¹ |
| æ¨å®šå·¥æ•° | 12æ—¥ |
| å„ªå…ˆåº¦ | ğŸŸ¡ ä¸­ |
| ä¾å­˜é–¢ä¿‚ | Phase 1, 2å®Œäº†æ¨å¥¨ |

### 5.2 ã‚¿ã‚¹ã‚¯ 2.1.1: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œæˆ (+12ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 5.2.1 é‡ã¿æœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/evidence/ensemble.py
  è¿½åŠ :
    class EnsembleClassifier:
        def __init__(
            self,
            rule_weight: float = 0.4,
            llm_weight: float = 0.6,
            use_confidence_weighting: bool = True,
        ):
            self._rule_classifier = RuleBasedClassifier()
            self._llm_classifier = LLMBasedClassifier()
            self._rule_weight = rule_weight
            self._llm_weight = llm_weight
            self._use_confidence = use_confidence_weighting
        
        def classify(self, title: str, abstract: str) -> EvidenceGrade:
            rule_result = self._rule_classifier.classify(title, abstract)
            llm_result = self._llm_classifier.classify(title, abstract)
            
            if self._use_confidence:
                # ä¿¡é ¼åº¦ã«åŸºã¥ãå‹•çš„é‡ã¿ä»˜ã‘
                total_confidence = rule_result.confidence + llm_result.confidence
                rule_w = rule_result.confidence / total_confidence
                llm_w = llm_result.confidence / total_confidence
            else:
                rule_w = self._rule_weight
                llm_w = self._llm_weight
            
            # åŠ é‡å¹³å‡ã§ãƒ¬ãƒ™ãƒ«æ±ºå®š
            level_scores = self._calculate_level_scores(rule_result, llm_result, rule_w, llm_w)
            best_level = max(level_scores, key=level_scores.get)
            
            return EvidenceGrade(
                level=best_level,
                confidence=level_scores[best_level],
                reasoning=f"Rule: {rule_result.level.value}, LLM: {llm_result.level.value}",
                method="ensemble",
            )
  æ¤œè¨¼: pytest tests/evidence/test_ensemble.py -v

â–¡ 5.2.2 ãƒãƒƒãƒã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æœ€é©åŒ– (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/evidence/ensemble.py
  è¿½åŠ :
    def classify_batch(self, papers: List[Dict[str, str]]) -> List[EvidenceGrade]:
        # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã¯ãƒãƒƒãƒå‡¦ç†
        rule_results = [self._rule_classifier.classify(p['title'], p['abstract']) for p in papers]
        
        # LLMã¯ãƒãƒƒãƒã§åŠ¹ç‡åŒ–
        llm_results = self._llm_classifier.classify_batch(papers)
        
        return [
            self._combine_results(rule, llm)
            for rule, llm in zip(rule_results, llm_results)
        ]
  æ¤œè¨¼: ãƒãƒƒãƒå‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

â–¡ 5.2.3 ãƒ†ã‚¹ãƒˆå¼·åŒ– (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/evidence/test_ensemble.py
  æ¤œè¨¼: pytest tests/evidence/ -v --cov
```

---

### 5.3 ã‚¿ã‚¹ã‚¯ 2.1.2: ä¿¡é ¼åº¦å¯è¦–åŒ– (+15ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 5.3.1 ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è©³ç´°å‡ºåŠ› (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/evidence/schema.py
  è¿½åŠ :
    @dataclass
    class DetailedEvidenceGrade(EvidenceGrade):
        rule_confidence: float = 0.0
        llm_confidence: float = 0.0
        level_probabilities: Dict[str, float] = field(default_factory=dict)
        
        def to_visualization_dict(self) -> Dict[str, Any]:
            return {
                "level": self.level.value,
                "level_description": self.level.description,
                "confidence": self.confidence,
                "components": {
                    "rule_based": self.rule_confidence,
                    "llm_based": self.llm_confidence,
                },
                "probabilities": self.level_probabilities,
            }
  æ¤œè¨¼: python -c "from jarvis_core.evidence import DetailedEvidenceGrade"

â–¡ 5.3.2 Mermaidã‚°ãƒ©ãƒ•ç”Ÿæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/evidence/visualizer.py
  å†…å®¹:
    class EvidenceVisualizer:
        def generate_confidence_chart(self, grades: List[DetailedEvidenceGrade]) -> str:
            """Mermaidãƒ‘ã‚¤ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ"""
            level_counts = {}
            for grade in grades:
                level = grade.level.value
                level_counts[level] = level_counts.get(level, 0) + 1
            
            mermaid = "pie title Evidence Level Distribution\n"
            for level, count in level_counts.items():
                mermaid += f'    "{level}" : {count}\n'
            
            return mermaid
        
        def generate_confidence_bar(self, grade: DetailedEvidenceGrade) -> str:
            """å˜ä¸€ã‚°ãƒ¬ãƒ¼ãƒ‰ã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"""
            probs = grade.level_probabilities
            
            mermaid = "xychart-beta\n"
            mermaid += '    title "Level Probabilities"\n'
            mermaid += f'    x-axis [{", ".join(probs.keys())}]\n'
            mermaid += f'    y-axis "Probability" 0 --> 1\n'
            mermaid += f'    bar [{", ".join(str(v) for v in probs.values())}]\n'
            
            return mermaid
  æ¤œè¨¼: pytest tests/evidence/test_visualizer.py -v

â–¡ 5.3.3 CLIå¯è¦–åŒ–ã‚³ãƒãƒ³ãƒ‰ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ :
    @cli.command()
    @click.argument('paper_file')
    @click.option('--output', '-o', default='evidence_report.md')
    def grade_evidence(paper_file: str, output: str):
        """Grade evidence levels for papers and generate visualization."""
        from jarvis_core.evidence import grade_evidence, EvidenceVisualizer
        
        papers = load_papers(paper_file)
        grades = [grade_evidence(p['title'], p['abstract']) for p in papers]
        
        visualizer = EvidenceVisualizer()
        
        with open(output, 'w') as f:
            f.write("# Evidence Grading Report\n\n")
            f.write("## Distribution\n\n")
            f.write("```mermaid\n")
            f.write(visualizer.generate_confidence_chart(grades))
            f.write("```\n\n")
            
            f.write("## Details\n\n")
            for paper, grade in zip(papers, grades):
                f.write(f"### {paper['title']}\n")
                f.write(f"- Level: {grade.level.value}\n")
                f.write(f"- Confidence: {grade.confidence:.2%}\n\n")
        
        click.echo(f"Report generated: {output}")
  æ¤œè¨¼: jarvis grade-evidence papers.json -o report.md

â–¡ 5.3.4 ãƒ†ã‚¹ãƒˆä½œæˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/evidence/test_visualizer.py
  æ¤œè¨¼: pytest tests/evidence/test_visualizer.py -v
```

---

### 5.4 ã‚¿ã‚¹ã‚¯ 2.2.1: Support/Contraståˆ†é¡å®Œæˆ (+20ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 5.4.1 ã‚¹ã‚¿ãƒ³ã‚¹åˆ†é¡å™¨å¼·åŒ– (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/citation/stance_classifier.py
  è¿½åŠ /å¤‰æ›´:
    class CitationStance(Enum):
        SUPPORT = "support"
        CONTRAST = "contrast"
        MENTION = "mention"
        COMPARE = "compare"
        EXTEND = "extend"
        BACKGROUND = "background"
    
    class StanceClassifier:
        def __init__(self):
            self._support_patterns = [
                r"confirm", r"support", r"consistent with", r"in line with",
                r"agree", r"corroborate", r"validate", r"reinforce",
            ]
            self._contrast_patterns = [
                r"contradict", r"contrary to", r"inconsistent", r"disagree",
                r"challenge", r"refute", r"oppose", r"conflict",
            ]
            self._compare_patterns = [
                r"compared to", r"in contrast to", r"unlike", r"whereas",
                r"however", r"although", r"while",
            ]
        
        def classify(self, context: CitationContext) -> StanceClassificationResult:
            text = context.get_full_context().lower()
            
            support_score = self._match_patterns(text, self._support_patterns)
            contrast_score = self._match_patterns(text, self._contrast_patterns)
            compare_score = self._match_patterns(text, self._compare_patterns)
            
            if contrast_score > support_score and contrast_score > compare_score:
                stance = CitationStance.CONTRAST
                confidence = min(contrast_score / 3, 1.0)
            elif support_score > contrast_score and support_score > compare_score:
                stance = CitationStance.SUPPORT
                confidence = min(support_score / 3, 1.0)
            elif compare_score > 0:
                stance = CitationStance.COMPARE
                confidence = min(compare_score / 3, 1.0)
            else:
                stance = CitationStance.MENTION
                confidence = 0.5
            
            return StanceClassificationResult(
                stance=stance,
                confidence=confidence,
                reasoning=f"Pattern scores: support={support_score}, contrast={contrast_score}",
            )
        
        def _match_patterns(self, text: str, patterns: List[str]) -> int:
            return sum(1 for p in patterns if re.search(p, text))
  æ¤œè¨¼: pytest tests/citation/test_stance_classifier.py -v

â–¡ 5.4.2 LLMãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨è¿½åŠ  (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/citation/llm_stance.py
  å†…å®¹:
    class LLMStanceClassifier:
        def __init__(self):
            from jarvis_core.llm import get_router
            self._router = get_router()
        
        def classify(self, context: CitationContext) -> StanceClassificationResult:
            prompt = f"""Classify the citation stance in the following context.

Context: {context.get_full_context()}

Classify as one of:
- SUPPORT: The citing paper agrees with or builds upon the cited work
- CONTRAST: The citing paper disagrees or presents conflicting findings
- MENTION: Neutral reference without strong agreement or disagreement
- COMPARE: Comparing methodologies or results

Respond with JSON: {{"stance": "...", "confidence": 0.0-1.0, "reasoning": "..."}}"""
            
            response = self._router.generate(prompt, max_tokens=200)
            return self._parse_response(response)
  æ¤œè¨¼: pytest tests/citation/test_llm_stance.py -v

â–¡ 5.4.3 ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/citation/stance_ensemble.py
  å†…å®¹:
    class EnsembleStanceClassifier:
        def __init__(self, rule_weight: float = 0.4, llm_weight: float = 0.6):
            self._rule = StanceClassifier()
            self._llm = LLMStanceClassifier()
            self._rule_weight = rule_weight
            self._llm_weight = llm_weight
        
        def classify(self, context: CitationContext) -> StanceClassificationResult:
            rule_result = self._rule.classify(context)
            llm_result = self._llm.classify(context)
            
            # ä¸€è‡´ã—ã¦ã„ã‚Œã°é«˜ä¿¡é ¼
            if rule_result.stance == llm_result.stance:
                confidence = min((rule_result.confidence + llm_result.confidence) / 2 + 0.2, 1.0)
                return StanceClassificationResult(
                    stance=rule_result.stance,
                    confidence=confidence,
                    reasoning=f"Consensus: {rule_result.stance.value}",
                )
            
            # LLMã‚’å„ªå…ˆï¼ˆãŸã ã—ãƒ«ãƒ¼ãƒ«ã®ä¿¡é ¼åº¦ãŒé«˜ã‘ã‚Œã°ãƒ«ãƒ¼ãƒ«ï¼‰
            if rule_result.confidence > 0.8:
                return rule_result
            return llm_result
  æ¤œè¨¼: pytest tests/citation/test_stance_ensemble.py -v

â–¡ 5.4.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/citation/test_stance_*.py
  æ¤œè¨¼: pytest tests/citation/ -v --cov
```

---

### 5.5 ã‚¿ã‚¹ã‚¯ 2.2.2: å¼•ç”¨å½±éŸ¿åŠ›ã‚¹ã‚³ã‚¢ (+15ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 5.5.1 å½±éŸ¿åŠ›è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/citation/influence.py
  å†…å®¹:
    from dataclasses import dataclass
    from typing import Dict, List
    
    @dataclass
    class InfluenceScore:
        paper_id: str
        total_citations: int
        support_count: int
        contrast_count: int
        mention_count: int
        influence_score: float
        controversy_score: float
    
    class InfluenceCalculator:
        def __init__(self, citation_graph: CitationGraph):
            self._graph = citation_graph
        
        def calculate(self, paper_id: str) -> InfluenceScore:
            citations = self._graph.get_citations(paper_id)
            
            support = sum(1 for c in citations if c.stance == CitationStance.SUPPORT)
            contrast = sum(1 for c in citations if c.stance == CitationStance.CONTRAST)
            mention = sum(1 for c in citations if c.stance == CitationStance.MENTION)
            
            total = len(citations)
            
            # å½±éŸ¿åŠ›ã‚¹ã‚³ã‚¢: è¢«å¼•ç”¨æ•° * (æ”¯æŒç‡ + 0.5 * å¯¾ç…§ç‡)
            support_rate = support / total if total > 0 else 0
            contrast_rate = contrast / total if total > 0 else 0
            
            influence = total * (support_rate + 0.5 * contrast_rate)
            
            # è­°è«–æ€§ã‚¹ã‚³ã‚¢: å¯¾ç…§å¼•ç”¨ã®å‰²åˆ
            controversy = contrast_rate
            
            return InfluenceScore(
                paper_id=paper_id,
                total_citations=total,
                support_count=support,
                contrast_count=contrast,
                mention_count=mention,
                influence_score=influence,
                controversy_score=controversy,
            )
  æ¤œè¨¼: pytest tests/citation/test_influence.py -v

â–¡ 5.5.2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ©Ÿèƒ½ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/citation/influence.py
  è¿½åŠ :
    def rank_papers(self, paper_ids: List[str], by: str = "influence") -> List[InfluenceScore]:
        scores = [self.calculate(pid) for pid in paper_ids]
        
        if by == "influence":
            return sorted(scores, key=lambda x: x.influence_score, reverse=True)
        elif by == "controversy":
            return sorted(scores, key=lambda x: x.controversy_score, reverse=True)
        elif by == "citations":
            return sorted(scores, key=lambda x: x.total_citations, reverse=True)
        
        return scores
  æ¤œè¨¼: pytest tests/citation/test_influence.py::test_ranking -v

â–¡ 5.5.3 CLIã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ :
    @cli.command()
    @click.argument('paper_ids', nargs=-1)
    @click.option('--by', default='influence', type=click.Choice(['influence', 'controversy', 'citations']))
    def rank_influence(paper_ids: Tuple[str], by: str):
        """Rank papers by influence score."""
        ...
  æ¤œè¨¼: jarvis rank-influence paper1 paper2 --by influence

â–¡ 5.5.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/citation/test_influence.py
  æ¤œè¨¼: pytest tests/citation/test_influence.py -v
```

---

### 5.6 ã‚¿ã‚¹ã‚¯ 2.3.1: çŸ›ç›¾è§£æ±ºææ¡ˆ (+20ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 5.6.1 è§£æ±ºææ¡ˆã‚¹ã‚­ãƒ¼ãƒ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/contradiction/resolution.py
  å†…å®¹:
    from dataclasses import dataclass
    from enum import Enum
    from typing import List, Optional
    
    class ResolutionStrategy(Enum):
        METHODOLOGY = "methodology"  # æ–¹æ³•è«–ã®é•ã„
        POPULATION = "population"    # å¯¾è±¡é›†å›£ã®é•ã„
        TIMEFRAME = "timeframe"      # æ™‚æœŸã®é•ã„
        MEASURE = "measure"          # æ¸¬å®šæ–¹æ³•ã®é•ã„
        CONTEXT = "context"          # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é•ã„
        UNKNOWN = "unknown"
    
    @dataclass
    class ResolutionSuggestion:
        strategy: ResolutionStrategy
        explanation: str
        confidence: float
        evidence_for: List[str]
        evidence_against: List[str]
        recommended_action: str
  æ¤œè¨¼: python -c "from jarvis_core.contradiction.resolution import ResolutionSuggestion"

â–¡ 5.6.2 è§£æ±ºææ¡ˆç”Ÿæˆå™¨ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/contradiction/resolver.py
  å†…å®¹:
    class ContradictionResolver:
        def __init__(self):
            from jarvis_core.llm import get_router
            self._router = get_router()
        
        def suggest_resolution(
            self,
            contradiction: ContradictionResult,
            claim_a_context: str,
            claim_b_context: str,
        ) -> ResolutionSuggestion:
            prompt = f"""Analyze the contradiction and suggest resolution:

Claim A: {contradiction.claim_a.text}
Context A: {claim_a_context}

Claim B: {contradiction.claim_b.text}
Context B: {claim_b_context}

Contradiction Type: {contradiction.contradiction_type.value}

Suggest how this contradiction might be resolved. Consider:
1. Different methodologies
2. Different study populations
3. Different time periods
4. Different measurement approaches
5. Different contexts

Respond with JSON:
{{
    "strategy": "methodology|population|timeframe|measure|context|unknown",
    "explanation": "...",
    "confidence": 0.0-1.0,
    "evidence_for": ["..."],
    "evidence_against": ["..."],
    "recommended_action": "..."
}}"""
            
            response = self._router.generate(prompt, max_tokens=500)
            return self._parse_response(response)
  æ¤œè¨¼: pytest tests/contradiction/test_resolver.py -v

â–¡ 5.6.3 ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹è£œåŠ©è§£æ±º (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/contradiction/resolver.py
  è¿½åŠ :
    def _rule_based_suggestion(self, contradiction: ContradictionResult) -> Optional[ResolutionStrategy]:
        text_a = contradiction.claim_a.text.lower()
        text_b = contradiction.claim_b.text.lower()
        
        # æ•°å€¤ã®é•ã„ â†’ æ¸¬å®šæ–¹æ³•
        if re.search(r'\d+%', text_a) and re.search(r'\d+%', text_b):
            return ResolutionStrategy.MEASURE
        
        # æ™‚é–“è¡¨ç¾ â†’ æ™‚æœŸ
        time_patterns = [r'\d{4}', r'year', r'month', r'recent']
        if any(re.search(p, text_a) for p in time_patterns):
            return ResolutionStrategy.TIMEFRAME
        
        # é›†å›£è¡¨ç¾ â†’ å¯¾è±¡é›†å›£
        population_patterns = [r'patients?', r'subjects?', r'participants?', r'adults?', r'children']
        if any(re.search(p, text_a) for p in population_patterns):
            return ResolutionStrategy.POPULATION
        
        return None
  æ¤œè¨¼: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹è§£æ±ºã®ãƒ†ã‚¹ãƒˆ

â–¡ 5.6.4 çŸ›ç›¾ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/contradiction/report.py
  å†…å®¹:
    class ContradictionReportGenerator:
        def generate(self, contradictions: List[ContradictionResult], resolutions: List[ResolutionSuggestion]) -> str:
            report = "# Contradiction Analysis Report\n\n"
            
            for i, (cont, res) in enumerate(zip(contradictions, resolutions)):
                report += f"## Contradiction {i+1}\n\n"
                report += f"**Claim A**: {cont.claim_a.text}\n"
                report += f"**Claim B**: {cont.claim_b.text}\n"
                report += f"**Type**: {cont.contradiction_type.value}\n\n"
                
                report += "### Resolution Suggestion\n\n"
                report += f"**Strategy**: {res.strategy.value}\n"
                report += f"**Explanation**: {res.explanation}\n"
                report += f"**Confidence**: {res.confidence:.0%}\n"
                report += f"**Recommended Action**: {res.recommended_action}\n\n"
                report += "---\n\n"
            
            return report
  æ¤œè¨¼: pytest tests/contradiction/test_report.py -v

â–¡ 5.6.5 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/contradiction/test_resolver.py, test_report.py
  æ¤œè¨¼: pytest tests/contradiction/ -v --cov
```

---

### 5.7 ã‚¿ã‚¹ã‚¯ 2.4.1: PRISMAå®Œå…¨æº–æ‹  (+12ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 5.7.1 PRISMA 2020ã‚¹ã‚­ãƒ¼ãƒå®Œå…¨å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/prisma/schema.py
  è¿½åŠ :
    @dataclass
    class PRISMA2020Data:
        """PRISMA 2020 compliant data structure."""
        
        # Identification
        records_identified_databases: int = 0
        records_identified_registers: int = 0
        records_identified_other: int = 0
        
        # Deduplication
        records_removed_duplicates: int = 0
        records_removed_automation: int = 0
        records_removed_other: int = 0
        
        # Screening
        records_screened: int = 0
        records_excluded_screening: int = 0
        
        # Eligibility
        reports_sought_retrieval: int = 0
        reports_not_retrieved: int = 0
        reports_assessed_eligibility: int = 0
        reports_excluded_eligibility: int = 0
        exclusion_reasons: Dict[str, int] = field(default_factory=dict)
        
        # Included
        studies_included_review: int = 0
        reports_included_review: int = 0
        
        # New studies from other methods
        records_identified_citation: int = 0
        records_identified_websites: int = 0
        records_identified_organisations: int = 0
        reports_sought_citation: int = 0
        reports_not_retrieved_citation: int = 0
        reports_assessed_citation: int = 0
        reports_excluded_citation: int = 0
        
        def validate(self) -> List[str]:
            """Validate PRISMA data consistency."""
            errors = []
            
            total_identified = (
                self.records_identified_databases +
                self.records_identified_registers +
                self.records_identified_other
            )
            
            total_removed = (
                self.records_removed_duplicates +
                self.records_removed_automation +
                self.records_removed_other
            )
            
            if self.records_screened > total_identified - total_removed:
                errors.append("Screened records exceed available after deduplication")
            
            return errors
  æ¤œè¨¼: pytest tests/prisma/test_schema.py -v

â–¡ 5.7.2 PRISMA 2020ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/prisma/generator.py
  æ›´æ–°:
    def generate_prisma_2020_flow(self, data: PRISMA2020Data) -> str:
        """Generate PRISMA 2020 compliant flow diagram in Mermaid."""
        
        mermaid = """flowchart TD
    subgraph identification["Identification"]
        db["Records from databases<br>(n = {db})"]
        reg["Records from registers<br>(n = {reg})"]
        other["Records from other sources<br>(n = {other})"]
    end
    
    subgraph screening["Screening"]
        dup["Records removed before screening:<br>Duplicates (n = {dup})<br>Automation (n = {auto})<br>Other (n = {other_rm})"]
        screened["Records screened<br>(n = {screened})"]
        excluded_screen["Records excluded<br>(n = {excl_screen})"]
    end
    
    subgraph eligibility["Eligibility"]
        sought["Reports sought<br>(n = {sought})"]
        not_retrieved["Reports not retrieved<br>(n = {not_ret})"]
        assessed["Reports assessed<br>(n = {assessed})"]
        excluded_elig["Reports excluded:<br>{exclusion_reasons}"]
    end
    
    subgraph included["Included"]
        studies["Studies in review<br>(n = {studies})"]
        reports["Reports in review<br>(n = {reports})"]
    end
    
    db --> dup
    reg --> dup
    other --> dup
    dup --> screened
    screened --> excluded_screen
    screened --> sought
    sought --> not_retrieved
    sought --> assessed
    assessed --> excluded_elig
    assessed --> studies
    studies --> reports
""".format(
            db=data.records_identified_databases,
            reg=data.records_identified_registers,
            other=data.records_identified_other,
            dup=data.records_removed_duplicates,
            auto=data.records_removed_automation,
            other_rm=data.records_removed_other,
            screened=data.records_screened,
            excl_screen=data.records_excluded_screening,
            sought=data.reports_sought_retrieval,
            not_ret=data.reports_not_retrieved,
            assessed=data.reports_assessed_eligibility,
            exclusion_reasons=self._format_exclusion_reasons(data.exclusion_reasons),
            studies=data.studies_included_review,
            reports=data.reports_included_review,
        )
        
        return mermaid
  æ¤œè¨¼: pytest tests/prisma/test_generator.py -v

â–¡ 5.7.3 ãƒ†ã‚¹ãƒˆä½œæˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/prisma/test_prisma_2020.py
  æ¤œè¨¼: pytest tests/prisma/ -v --cov
```

---

## 6. Phase 4: ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ å®Œæˆ (+96ç‚¹)

### 6.1 æ¦‚è¦

| é …ç›® | å€¤ |
|------|-----|
| ç›®æ¨™ã‚¹ã‚³ã‚¢ | +96ç‚¹ |
| æ¨å®šå·¥æ•° | 10æ—¥ |
| å„ªå…ˆåº¦ | ğŸŸ¢ é€šå¸¸ |
| ä¾å­˜é–¢ä¿‚ | Phase 1-3å®Œäº†æ¨å¥¨ |

### 6.2 ã‚¿ã‚¹ã‚¯ 3.1.1: Zoteroé€£æº (+25ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 6.2.1 Zotero APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/integrations/zotero.py
  å†…å®¹:
    from dataclasses import dataclass
    from typing import Any, Dict, List, Optional
    import requests
    
    @dataclass
    class ZoteroConfig:
        api_key: str
        user_id: str
        library_type: str = "user"  # "user" or "group"
    
    class ZoteroClient:
        BASE_URL = "https://api.zotero.org"
        
        def __init__(self, config: ZoteroConfig):
            self._config = config
            self._headers = {
                "Zotero-API-Key": config.api_key,
                "Zotero-API-Version": "3",
            }
        
        def _get_library_url(self) -> str:
            if self._config.library_type == "user":
                return f"{self.BASE_URL}/users/{self._config.user_id}"
            return f"{self.BASE_URL}/groups/{self._config.user_id}"
        
        def get_items(self, collection_key: Optional[str] = None, limit: int = 100) -> List[Dict]:
            url = f"{self._get_library_url()}/items"
            params = {"limit": limit, "format": "json"}
            if collection_key:
                params["collection"] = collection_key
            
            response = requests.get(url, headers=self._headers, params=params)
            response.raise_for_status()
            return response.json()
        
        def create_item(self, item_data: Dict[str, Any]) -> Dict:
            url = f"{self._get_library_url()}/items"
            response = requests.post(url, headers=self._headers, json=[item_data])
            response.raise_for_status()
            return response.json()
        
        def get_collections(self) -> List[Dict]:
            url = f"{self._get_library_url()}/collections"
            response = requests.get(url, headers=self._headers)
            response.raise_for_status()
            return response.json()
        
        def search(self, query: str, limit: int = 25) -> List[Dict]:
            url = f"{self._get_library_url()}/items"
            params = {"q": query, "limit": limit, "format": "json"}
            response = requests.get(url, headers=self._headers, params=params)
            response.raise_for_status()
            return response.json()
  æ¤œè¨¼: pytest tests/integrations/test_zotero.py -v

â–¡ 6.2.2 Zoteroãƒ—ãƒ©ã‚°ã‚¤ãƒ³å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/plugins/zotero_plugin.py
  å†…å®¹:
    from jarvis_core.plugins import PluginProtocol, PluginManifest
    from jarvis_core.integrations.zotero import ZoteroClient, ZoteroConfig
    
    class ZoteroPlugin(PluginProtocol):
        @property
        def manifest(self) -> PluginManifest:
            return PluginManifest(
                name="zotero",
                version="1.0.0",
                description="Zotero reference manager integration",
                author="JARVIS Team",
                plugin_type="integration",
            )
        
        def initialize(self, config: Dict[str, Any]) -> None:
            zotero_config = ZoteroConfig(
                api_key=config["api_key"],
                user_id=config["user_id"],
                library_type=config.get("library_type", "user"),
            )
            self._client = ZoteroClient(zotero_config)
        
        def import_references(self, collection_key: Optional[str] = None) -> List[Dict]:
            items = self._client.get_items(collection_key)
            return [self._convert_to_paper(item) for item in items]
        
        def export_references(self, papers: List[Dict], collection_key: Optional[str] = None) -> int:
            exported = 0
            for paper in papers:
                item_data = self._convert_to_zotero(paper)
                self._client.create_item(item_data)
                exported += 1
            return exported
        
        def _convert_to_paper(self, zotero_item: Dict) -> Dict:
            data = zotero_item.get("data", {})
            return {
                "id": zotero_item.get("key"),
                "title": data.get("title", ""),
                "authors": [c.get("lastName", "") for c in data.get("creators", [])],
                "abstract": data.get("abstractNote", ""),
                "doi": data.get("DOI"),
                "year": data.get("date", "")[:4] if data.get("date") else None,
                "source": "zotero",
            }
        
        def _convert_to_zotero(self, paper: Dict) -> Dict:
            return {
                "itemType": "journalArticle",
                "title": paper.get("title", ""),
                "creators": [{"creatorType": "author", "lastName": a} for a in paper.get("authors", [])],
                "abstractNote": paper.get("abstract", ""),
                "DOI": paper.get("doi"),
                "date": paper.get("year"),
            }
  æ¤œè¨¼: pytest tests/plugins/test_zotero_plugin.py -v

â–¡ 6.2.3 CLIã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ :
    @cli.group()
    def zotero():
        """Zotero integration commands."""
        pass
    
    @zotero.command()
    @click.option('--collection', '-c', help='Zotero collection key')
    @click.option('--output', '-o', default='papers.json')
    def import_refs(collection: Optional[str], output: str):
        """Import references from Zotero."""
        from jarvis_core.plugins import get_plugin_manager
        
        manager = get_plugin_manager()
        plugin = manager.get_plugin("zotero")
        
        papers = plugin.import_references(collection)
        
        with open(output, 'w') as f:
            json.dump(papers, f, indent=2)
        
        click.echo(f"Imported {len(papers)} references to {output}")
    
    @zotero.command()
    @click.argument('papers_file')
    @click.option('--collection', '-c', help='Target Zotero collection')
    def export_refs(papers_file: str, collection: Optional[str]):
        """Export references to Zotero."""
        from jarvis_core.plugins import get_plugin_manager
        
        with open(papers_file) as f:
            papers = json.load(f)
        
        manager = get_plugin_manager()
        plugin = manager.get_plugin("zotero")
        
        count = plugin.export_references(papers, collection)
        click.echo(f"Exported {count} references to Zotero")
  æ¤œè¨¼: jarvis zotero import --collection ABC123 -o papers.json

â–¡ 6.2.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/integrations/test_zotero.py, tests/plugins/test_zotero_plugin.py
  æ¤œè¨¼: pytest tests/integrations/test_zotero.py tests/plugins/test_zotero_plugin.py -v
```

---

### 6.3 ã‚¿ã‚¹ã‚¯ 3.1.2: Mendeleyé€£æº (+20ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 6.3.1 Mendeley APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/integrations/mendeley.py
  å†…å®¹:
    class MendeleyClient:
        BASE_URL = "https://api.mendeley.com"
        
        def __init__(self, access_token: str):
            self._token = access_token
            self._headers = {
                "Authorization": f"Bearer {access_token}",
                "Accept": "application/vnd.mendeley-document.1+json",
            }
        
        def get_documents(self, folder_id: Optional[str] = None, limit: int = 100) -> List[Dict]:
            url = f"{self.BASE_URL}/documents"
            params = {"limit": limit}
            if folder_id:
                params["folder_id"] = folder_id
            
            response = requests.get(url, headers=self._headers, params=params)
            response.raise_for_status()
            return response.json()
        
        def create_document(self, document: Dict) -> Dict:
            url = f"{self.BASE_URL}/documents"
            response = requests.post(url, headers=self._headers, json=document)
            response.raise_for_status()
            return response.json()
        
        def search(self, query: str, limit: int = 25) -> List[Dict]:
            url = f"{self.BASE_URL}/search/catalog"
            params = {"query": query, "limit": limit}
            response = requests.get(url, headers=self._headers, params=params)
            response.raise_for_status()
            return response.json()
  æ¤œè¨¼: pytest tests/integrations/test_mendeley.py -v

â–¡ 6.3.2 Mendeleyãƒ—ãƒ©ã‚°ã‚¤ãƒ³å®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/plugins/mendeley_plugin.py
  å†…å®¹: Zoteroãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¨åŒæ§˜ã®æ§‹é€ ã§å®Ÿè£…
  æ¤œè¨¼: pytest tests/plugins/test_mendeley_plugin.py -v

â–¡ 6.3.3 CLIã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ : zoteroã¨åŒæ§˜ã®mendeley ã‚°ãƒ«ãƒ¼ãƒ—ã‚³ãƒãƒ³ãƒ‰
  æ¤œè¨¼: jarvis mendeley import -o papers.json

â–¡ 6.3.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  æ¤œè¨¼: pytest tests/integrations/test_mendeley.py -v
```

---

### 6.4 ã‚¿ã‚¹ã‚¯ 3.2.1: RIS/BibTeXå®Œå…¨å‡ºåŠ› (+12ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 6.4.1 RISãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿å®Œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/export/ris.py
  å†…å®¹:
    class RISExporter:
        TYPE_MAP = {
            "journal_article": "JOUR",
            "conference_paper": "CONF",
            "book": "BOOK",
            "thesis": "THES",
            "preprint": "UNPB",
        }
        
        def export(self, papers: List[Dict]) -> str:
            lines = []
            for paper in papers:
                lines.extend(self._format_paper(paper))
                lines.append("")  # Empty line between entries
            return "\n".join(lines)
        
        def _format_paper(self, paper: Dict) -> List[str]:
            lines = []
            
            paper_type = paper.get("type", "journal_article")
            lines.append(f"TY  - {self.TYPE_MAP.get(paper_type, 'JOUR')}")
            
            if paper.get("title"):
                lines.append(f"TI  - {paper['title']}")
            
            for author in paper.get("authors", []):
                lines.append(f"AU  - {author}")
            
            if paper.get("year"):
                lines.append(f"PY  - {paper['year']}")
            
            if paper.get("journal"):
                lines.append(f"JO  - {paper['journal']}")
            
            if paper.get("volume"):
                lines.append(f"VL  - {paper['volume']}")
            
            if paper.get("issue"):
                lines.append(f"IS  - {paper['issue']}")
            
            if paper.get("pages"):
                lines.append(f"SP  - {paper['pages']}")
            
            if paper.get("doi"):
                lines.append(f"DO  - {paper['doi']}")
            
            if paper.get("abstract"):
                lines.append(f"AB  - {paper['abstract']}")
            
            if paper.get("keywords"):
                for kw in paper['keywords']:
                    lines.append(f"KW  - {kw}")
            
            lines.append("ER  - ")
            
            return lines
        
        def export_to_file(self, papers: List[Dict], path: str) -> None:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(self.export(papers))
  æ¤œè¨¼: pytest tests/export/test_ris.py -v

â–¡ 6.4.2 BibTeXãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿å®Œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/export/bibtex.py
  å†…å®¹:
    class BibTeXExporter:
        def export(self, papers: List[Dict]) -> str:
            entries = [self._format_paper(paper) for paper in papers]
            return "\n\n".join(entries)
        
        def _format_paper(self, paper: Dict) -> str:
            entry_type = self._get_entry_type(paper.get("type", "article"))
            cite_key = self._generate_cite_key(paper)
            
            fields = []
            
            if paper.get("title"):
                fields.append(f'  title = {{{paper["title"]}}}')
            
            if paper.get("authors"):
                authors_str = " and ".join(paper["authors"])
                fields.append(f'  author = {{{authors_str}}}')
            
            if paper.get("year"):
                fields.append(f'  year = {{{paper["year"]}}}')
            
            if paper.get("journal"):
                fields.append(f'  journal = {{{paper["journal"]}}}')
            
            if paper.get("volume"):
                fields.append(f'  volume = {{{paper["volume"]}}}')
            
            if paper.get("pages"):
                fields.append(f'  pages = {{{paper["pages"]}}}')
            
            if paper.get("doi"):
                fields.append(f'  doi = {{{paper["doi"]}}}')
            
            if paper.get("abstract"):
                abstract = paper["abstract"].replace("{", "\\{").replace("}", "\\}")
                fields.append(f'  abstract = {{{abstract}}}')
            
            fields_str = ",\n".join(fields)
            return f"@{entry_type}{{{cite_key},\n{fields_str}\n}}"
        
        def _get_entry_type(self, paper_type: str) -> str:
            type_map = {
                "journal_article": "article",
                "conference_paper": "inproceedings",
                "book": "book",
                "thesis": "phdthesis",
                "preprint": "misc",
            }
            return type_map.get(paper_type, "article")
        
        def _generate_cite_key(self, paper: Dict) -> str:
            first_author = paper.get("authors", ["unknown"])[0].split()[-1].lower()
            year = paper.get("year", "0000")
            title_word = paper.get("title", "untitled").split()[0].lower()
            return f"{first_author}{year}{title_word}"
  æ¤œè¨¼: pytest tests/export/test_bibtex.py -v

â–¡ 6.4.3 çµ±åˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/export/__init__.py
  è¿½åŠ :
    from .ris import RISExporter
    from .bibtex import BibTeXExporter
    
    def export_papers(papers: List[Dict], format: str, path: str) -> None:
        if format == "ris":
            exporter = RISExporter()
        elif format == "bibtex":
            exporter = BibTeXExporter()
        else:
            raise ValueError(f"Unknown format: {format}")
        
        exporter.export_to_file(papers, path)
  æ¤œè¨¼: python -c "from jarvis_core.export import export_papers"

â–¡ 6.4.4 CLIã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ :
    @cli.command()
    @click.argument('papers_file')
    @click.option('--format', '-f', type=click.Choice(['ris', 'bibtex', 'json']), default='bibtex')
    @click.option('--output', '-o', required=True)
    def export(papers_file: str, format: str, output: str):
        """Export papers to various formats."""
        from jarvis_core.export import export_papers
        
        with open(papers_file) as f:
            papers = json.load(f)
        
        export_papers(papers, format, output)
        click.echo(f"Exported {len(papers)} papers to {output}")
  æ¤œè¨¼: jarvis export papers.json -f bibtex -o refs.bib

â–¡ 6.4.5 ãƒ†ã‚¹ãƒˆä½œæˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/export/test_ris.py, tests/export/test_bibtex.py
  æ¤œè¨¼: pytest tests/export/ -v --cov
```

---

### 6.5 ã‚¿ã‚¹ã‚¯ 3.2.2: CLIå®Œæˆ (+10ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 6.5.1 jarvis-screenæ”¹å–„ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/active_learning/cli.py
  è¿½åŠ :
    - é€²æ—è¡¨ç¤ºãƒãƒ¼
    - ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜/å†é–‹
  æ¤œè¨¼: jarvis-screen papers.json

â–¡ 6.5.2 ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ”¹å–„ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  å¤‰æ›´: å…¨ã‚³ãƒãƒ³ãƒ‰ã«examplesã¨è©³ç´°helpã‚’è¿½åŠ 
  æ¤œè¨¼: jarvis --help, jarvis search --help

â–¡ 6.5.3 ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»è¨­å®šã‚³ãƒãƒ³ãƒ‰è¿½åŠ  (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_cli.py
  è¿½åŠ :
    @cli.command()
    def version():
        """Show version information."""
        click.echo(f"JARVIS Research OS v{__version__}")
    
    @cli.command()
    def config():
        """Show current configuration."""
        from jarvis_core.config import get_config
        config = get_config()
        click.echo(yaml.dump(config, default_flow_style=False))
  æ¤œè¨¼: jarvis version, jarvis config

â–¡ 6.5.4 ãƒ†ã‚¹ãƒˆä½œæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/cli/test_commands.py
  æ¤œè¨¼: pytest tests/cli/ -v --cov
```

---

### 6.6 ã‚¿ã‚¹ã‚¯ 3.2.3: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œæˆ (+15ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 6.6.1 APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹è‡ªå‹•ç”Ÿæˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: docs/api/README.md (è‡ªå‹•ç”Ÿæˆ)
  æ–¹æ³•:
    pip install pdoc3
    pdoc --html jarvis_core -o docs/api
  æ¤œè¨¼: docs/api/ ã«HTMLãŒç”Ÿæˆã•ã‚Œã‚‹

â–¡ 6.6.2 ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰å®Œæˆ (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: docs/user_guide.md
  å†…å®¹:
    - ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †
    - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ
    - CLIä½¿ç”¨æ–¹æ³•
    - APIä½¿ç”¨ä¾‹
    - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
  æ¤œè¨¼: docs/user_guide.md ãŒå­˜åœ¨ã—å†…å®¹ãŒå®Œå…¨

â–¡ 6.6.3 é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰æ›´æ–° (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: docs/developer_guide.md
  å†…å®¹:
    - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª¬æ˜
    - ãƒ—ãƒ©ã‚°ã‚¤ãƒ³é–‹ç™ºæ–¹æ³•
    - ãƒ†ã‚¹ãƒˆæ–¹æ³•
    - ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•
  æ¤œè¨¼: docs/developer_guide.md ç¢ºèª

â–¡ 6.6.4 READMEæ›´æ–° (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: README.md
  è¿½åŠ :
    - å…¨æ©Ÿèƒ½ã®èª¬æ˜
    - ãƒãƒƒã‚¸æ›´æ–°
    - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆä¾‹
  æ¤œè¨¼: README.md ã®å†…å®¹ç¢ºèª

â–¡ 6.6.5 CHANGELOGä½œæˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: CHANGELOG.md
  å†…å®¹: v1.0.0ã¾ã§ã®å¤‰æ›´å±¥æ­´
  æ¤œè¨¼: CHANGELOG.md ç¢ºèª
```

---

### 6.7 ã‚¿ã‚¹ã‚¯ 3.3.1: CORE APIçµ±åˆ (+15ç‚¹)

#### ã‚µãƒ–ã‚¿ã‚¹ã‚¯

```
â–¡ 6.7.1 CORE APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®Ÿè£… (5åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sources/core_client.py
  å†…å®¹:
    class COREClient:
        BASE_URL = "https://api.core.ac.uk/v3"
        
        def __init__(self, api_key: str):
            self._api_key = api_key
            self._headers = {"Authorization": f"Bearer {api_key}"}
        
        def search(self, query: str, limit: int = 10) -> List[Dict]:
            url = f"{self.BASE_URL}/search/works"
            params = {"q": query, "limit": limit}
            response = requests.get(url, headers=self._headers, params=params)
            response.raise_for_status()
            return response.json().get("results", [])
        
        def get_work(self, core_id: str) -> Optional[Dict]:
            url = f"{self.BASE_URL}/works/{core_id}"
            response = requests.get(url, headers=self._headers)
            if response.status_code == 404:
                return None
            response.raise_for_status()
            return response.json()
        
        def get_fulltext(self, core_id: str) -> Optional[str]:
            work = self.get_work(core_id)
            if work and work.get("fullText"):
                return work["fullText"]
            return None
  æ¤œè¨¼: pytest tests/sources/test_core_client.py -v

â–¡ 6.7.2 UnifiedSourceClientã«çµ±åˆ (3åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: jarvis_core/sources/unified_client.py
  å¤‰æ›´:
    from .core_client import COREClient
    
    class UnifiedSourceClient:
        def __init__(self, ..., core_api_key: Optional[str] = None):
            ...
            if core_api_key:
                self._core = COREClient(core_api_key)
  æ¤œè¨¼: COREã‚’å«ã‚ãŸçµ±åˆæ¤œç´¢ãƒ†ã‚¹ãƒˆ

â–¡ 6.7.3 ãƒ†ã‚¹ãƒˆä½œæˆ (2åˆ†)
  ãƒ•ã‚¡ã‚¤ãƒ«: tests/sources/test_core_client.py
  æ¤œè¨¼: pytest tests/sources/test_core_client.py -v
```

---

## 7. æ¤œè¨¼ãƒ»å“è³ªä¿è¨¼

### 7.1 ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```
â–¡ å…¨ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆåˆæ ¼
  ã‚³ãƒãƒ³ãƒ‰: pytest tests/ -v
  åŸºæº–: 100% pass

â–¡ çµ±åˆãƒ†ã‚¹ãƒˆåˆæ ¼
  ã‚³ãƒãƒ³ãƒ‰: pytest tests/integration/ -v
  åŸºæº–: 100% pass

â–¡ ã‚«ãƒãƒ¬ãƒƒã‚¸80%ä»¥ä¸Š
  ã‚³ãƒãƒ³ãƒ‰: pytest --cov=jarvis_core --cov-report=html
  åŸºæº–: ã‚«ãƒãƒ¬ãƒƒã‚¸ >= 80%

â–¡ å‹ãƒã‚§ãƒƒã‚¯åˆæ ¼
  ã‚³ãƒãƒ³ãƒ‰: mypy jarvis_core/
  åŸºæº–: ã‚¨ãƒ©ãƒ¼ 0

â–¡ ãƒªãƒ³ã‚¿ãƒ¼åˆæ ¼
  ã‚³ãƒãƒ³ãƒ‰: ruff check jarvis_core/
  åŸºæº–: ã‚¨ãƒ©ãƒ¼ 0
```

### 7.2 E2Eãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª

```
â–¡ ã‚·ãƒŠãƒªã‚ª1: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è«–æ–‡æ¤œç´¢
  æ‰‹é †:
    1. jarvis --offline search "cancer treatment"
    2. æ¤œç´¢çµæœãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã•ã‚Œã‚‹
  æœŸå¾…: ã‚¨ãƒ©ãƒ¼ãªãçµæœè¡¨ç¤º

â–¡ ã‚·ãƒŠãƒªã‚ª2: è¨¼æ‹ ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
  æ‰‹é †:
    1. jarvis search "RCT diabetes" -o papers.json
    2. jarvis grade-evidence papers.json -o report.md
  æœŸå¾…: ãƒ¬ãƒãƒ¼ãƒˆã«å…¨è«–æ–‡ã®ã‚°ãƒ¬ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹

â–¡ ã‚·ãƒŠãƒªã‚ª3: Zoteroé€£æº
  æ‰‹é †:
    1. jarvis zotero import -c COLLECTION_KEY -o zotero_papers.json
    2. jarvis grade-evidence zotero_papers.json
    3. jarvis zotero export graded_papers.json
  æœŸå¾…: Zoteroã«è«–æ–‡ãŒè¿½åŠ ã•ã‚Œã‚‹

â–¡ ã‚·ãƒŠãƒªã‚ª4: PRISMAç”Ÿæˆ
  æ‰‹é †:
    1. jarvis run --goal "systematic review cancer immunotherapy"
    2. jarvis prisma --output prisma.svg
  æœŸå¾…: æœ‰åŠ¹ãªPRISMAãƒ•ãƒ­ãƒ¼å›³ãŒç”Ÿæˆã•ã‚Œã‚‹

â–¡ ã‚·ãƒŠãƒªã‚ª5: çŸ›ç›¾æ¤œå‡ºã¨è§£æ±º
  æ‰‹é †:
    1. jarvis detect-contradictions papers.json -o contradictions.json
    2. jarvis resolve-contradictions contradictions.json -o resolutions.md
  æœŸå¾…: è§£æ±ºææ¡ˆã‚’å«ã‚€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
```

---

## 8. å®Œäº†åˆ¤å®šåŸºæº–

### 8.1 ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Œäº†åŸºæº–

```yaml
Phase 1 (ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰):
  criteria:
    - DegradationManagerå®Ÿè£…å®Œäº†
    - --offlineãƒ•ãƒ©ã‚°å‹•ä½œç¢ºèª
    - SyncQueueå®Ÿè£…å®Œäº†
    - è‡ªå‹•åŒæœŸå‹•ä½œç¢ºèª
    - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >= 80%
  score_target: "+80ç‚¹"

Phase 2 (åŸ‹ã‚è¾¼ã¿ãƒ»æ¤œç´¢):
  criteria:
    - SPECTER2çµ±åˆå®Œäº†
    - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢RRFå‹•ä½œç¢ºèª
    - FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å‹•ä½œç¢ºèª
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®å‹•ä½œç¢ºèª
    - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >= 80%
  score_target: "+46ç‚¹"

Phase 3 (å·®åˆ¥åŒ–æ©Ÿèƒ½):
  criteria:
    - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç²¾åº¦ >= 85%
    - Support/Contraståˆ†é¡ç²¾åº¦ >= 80%
    - çŸ›ç›¾è§£æ±ºææ¡ˆç”Ÿæˆç¢ºèª
    - PRISMA 2020æº–æ‹ ç¢ºèª
    - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >= 80%
  score_target: "+100ç‚¹"

Phase 4 (ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ):
  criteria:
    - Zoteroé€£æºå‹•ä½œç¢ºèª
    - Mendeleyé€£æºå‹•ä½œç¢ºèª
    - RIS/BibTeXå‡ºåŠ›å‹•ä½œç¢ºèª
    - CLIå…¨ã‚³ãƒãƒ³ãƒ‰å‹•ä½œç¢ºèª
    - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå‚™
    - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >= 80%
  score_target: "+96ç‚¹"
```

### 8.2 æœ€çµ‚ãƒªãƒªãƒ¼ã‚¹åŸºæº–

```yaml
release_criteria:
  functional:
    - å…¨Phaseå®Œäº†
    - E2Eãƒ†ã‚¹ãƒˆå…¨ã‚·ãƒŠãƒªã‚ªåˆæ ¼
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå‚™
    
  quality:
    - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >= 80%
    - å‹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ 0
    - ãƒªãƒ³ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼ 0
    - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ 0
    
  performance:
    - æ¤œç´¢ãƒ¬ã‚¹ãƒãƒ³ã‚¹ < 2ç§’ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚)
    - ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° < 5ç§’/è«–æ–‡
    - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ < 2GB (1000è«–æ–‡å‡¦ç†æ™‚)
    
  documentation:
    - README.md å®Œå‚™
    - APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ å®Œå‚™
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰ å®Œå‚™
    - CHANGELOG å®Œå‚™
```

---

## ä»˜éŒ²A: ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```
æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:

Phase 1:
â–¡ jarvis_core/network/degradation.py
â–¡ jarvis_core/network/api_wrapper.py
â–¡ jarvis_core/network/listener.py
â–¡ jarvis_core/sync/__init__.py
â–¡ jarvis_core/sync/schema.py
â–¡ jarvis_core/sync/storage.py
â–¡ jarvis_core/sync/manager.py
â–¡ jarvis_core/sync/handlers.py
â–¡ jarvis_core/sync/auto_sync.py
â–¡ jarvis_core/sync/progress.py
â–¡ jarvis_core/ui/status.py
â–¡ tests/network/test_degradation.py
â–¡ tests/network/test_api_wrapper.py
â–¡ tests/network/test_listener.py
â–¡ tests/sync/test_*.py
â–¡ tests/cli/test_offline_flag.py

Phase 2:
â–¡ jarvis_core/embeddings/specter2.py
â–¡ jarvis_core/embeddings/vector_store.py
â–¡ tests/embeddings/test_specter2.py
â–¡ tests/embeddings/test_vector_store.py
â–¡ tests/embeddings/test_hybrid.py
â–¡ tests/cache/test_compression.py
â–¡ tests/cache/test_lru.py

Phase 3:
â–¡ jarvis_core/evidence/visualizer.py
â–¡ jarvis_core/citation/llm_stance.py
â–¡ jarvis_core/citation/stance_ensemble.py
â–¡ jarvis_core/citation/influence.py
â–¡ jarvis_core/contradiction/resolution.py
â–¡ jarvis_core/contradiction/resolver.py
â–¡ jarvis_core/contradiction/report.py
â–¡ tests/evidence/test_visualizer.py
â–¡ tests/citation/test_llm_stance.py
â–¡ tests/citation/test_influence.py
â–¡ tests/contradiction/test_resolver.py
â–¡ tests/contradiction/test_report.py
â–¡ tests/prisma/test_prisma_2020.py

Phase 4:
â–¡ jarvis_core/integrations/zotero.py
â–¡ jarvis_core/integrations/mendeley.py
â–¡ jarvis_core/plugins/zotero_plugin.py
â–¡ jarvis_core/plugins/mendeley_plugin.py
â–¡ jarvis_core/export/ris.py
â–¡ jarvis_core/export/bibtex.py
â–¡ jarvis_core/sources/core_client.py
â–¡ tests/integrations/test_zotero.py
â–¡ tests/integrations/test_mendeley.py
â–¡ tests/plugins/test_zotero_plugin.py
â–¡ tests/plugins/test_mendeley_plugin.py
â–¡ tests/export/test_ris.py
â–¡ tests/export/test_bibtex.py
â–¡ tests/sources/test_core_client.py
â–¡ docs/api/README.md
â–¡ docs/user_guide.md
â–¡ docs/developer_guide.md
â–¡ CHANGELOG.md
```

---

## ä»˜éŒ²B: ã‚¹ã‚³ã‚¢ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

```
é–‹å§‹æ™‚ã‚¹ã‚³ã‚¢: 878/1200 (73.2%)

Phase 1å®Œäº†å¾Œ: 958/1200 (79.8%) [+80]
Phase 2å®Œäº†å¾Œ: 1004/1200 (83.7%) [+46]
Phase 3å®Œäº†å¾Œ: 1104/1200 (92.0%) [+100]
Phase 4å®Œäº†å¾Œ: 1200/1200 (100%) [+96] âœ…

æœ€çµ‚ç›®æ¨™: 120/100ç‚¹ (1200/1000) é”æˆ
```

---

**æ–‡æ›¸çµ‚äº†**

---

> ã“ã®æŒ‡ç¤ºæ›¸ã¯ JARVIS Research OS ã® skills/ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ä½µç”¨ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
> å„ã‚¿ã‚¹ã‚¯ã¯ SPEC.md å½¢å¼ã§è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ORCH.md ã«ã‚ˆã‚‹ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
> å®Œäº†å¾Œã¯ VERIFY.md ã§æ¤œè¨¼ã—ã€FINISH.md ã§ãƒãƒ¼ã‚¸ã—ã¦ãã ã•ã„ã€‚

